## FIZYKA

1. **Co to jest ładunek elektryczny i jakie posiada właściwości?**

   Ładunek elektryczny to właściwość cząstek elementarnych, wyrażana w kulkombach (C). Ładunki mogą być dodatnie lub ujemne, a ładunki o przeciwnych znakach przyciągają się, a o tych samych znakach odpychają. Ładunek elektryczny jest zachowywany w zamkniętym układzie, co oznacza, że suma ładunków w układzie zawsze pozostaje stała.

1. **Jakie są podstawowe pojęcia obwodów elektrycznych?**

   Podstawowymi pojęciami obwodów elektrycznych są: prąd, potencjał, napięcie, energia, moc, rezystancja oraz impedancja. Prąd to przepływ ładunków przez przewodnik, wyrażany w amperach (A). Potencjał to energia przypisana ładunkowi elektrycznemu, wyrażona w woltach (V). Napięcie to różnica potencjałów między dwoma punktami w obwodzie, wyrażona w woltach (V). Energia to iloczyn mocy i czasu, wyrażony w dżulach (J). Moc to szybkość, z jaką energia jest przekazywana, wyrażona w watach (W). Rezystancja to opór, jaki dany materiał stawia przepływowi prądu, wyrażona w omach (Ω). Impedancja to całkowity opór obwodu, który uwzględnia opór oraz właściwości pojemnościowe i indukcyjne obwodu.

1. **Co to są pola magnetyczne, pola elektryczne i pola elektromagnetyczne i jakie mają zastosowanie w architekturze komputera?**

   Pole magnetyczne to pole, które powstaje wokół magnesu lub przepływającego przez przewodnik prądu elektrycznego. Pole elektryczne to pole, które powstaje wokół ładunków elektrycznych. Pole elektromagnetyczne to połączenie tych dwóch pól, co powoduje propagację fali elektromagnetycznej, która może przenosić informacje. W architekturze komputera, pola elektryczne i magnetyczne są wykorzystywane do przesyłania sygnałów między elementami elektronicznymi, takimi jak procesory, pamięć i interfejsy wejścia-wyjścia.

1. **Jakie są cechy i zakresy fal elektromagnetycznych i jak są one wykorzystywane w przesyłaniu sygnału?**

   Fale elektromagnetyczne to fale propagujące się w próżni, które składają się z pól elektrycznych i magnetycznych, propagujących się prostopadle do siebie. Cechy fal elektromagnetycznych to długość fali, częstotliwość, energia, amplituda, polaryzacja i prędkość propagacji. Zakres fal elektromagnetycznych obejmuje fale radiowe, mikrofale, podczerwień, światło widzialne, promieniowanie ultrafioletowe, promieniowanie rentgenowskie i promieniowanie gamma. Fale elektromagnetyczne są wykorzystywane w przesyłaniu sygnału w różnych technologiach, takich jak radio, telewizja, telekomunikacja i sieci bezprzewodowe.

## PODSTAWY ELEKTROTECHNIKI I ELEKTRONIKI

1.  **Porównaj budowę i zasada działania diody półprzewodnikowej i diody Zenera.**

    Diody półprzewodnikowe i diody Zenera różnią się od siebie w zasadzie działania. Diody półprzewodnikowe działają jako prostowniki i pozwalają na przepływ prądu tylko w jednym kierunku, podczas gdy diody Zenera mają wbudowany obszar zaporowy, który pozwala na przepływ prądu w przeciwnym kierunku w określonym zakresie napięcia zwanym napięciem Zenera. Budowa diody półprzewodnikowej składa się z półprzewodnikowego kryształu z anodą i katodą, natomiast dioda Zenera ma zazwyczaj taki sam kształt jak dioda półprzewodnikowa, ale ma specjalny obszar zaporowy.

2.  **Porównaj budowę i zasada działania tranzystora bipolarnego i tranzystora polowego.**

    Tranzystory bipolarne i polowe różnią się w zasadzie działania, budowie i sposobie sterowania. Tranzystory bipolarne składają się z dwóch połączonych złączem p-n półprzewodników, natomiast tranzystory polowe składają się z jednego półprzewodnikowego kanału, który kontroluje przepływ prądu. Tranzystory bipolarne są sterowane prądem bazy, a tranzystory polowe napięciem bramki. Tranzystory bipolarne charakteryzują się dużą wzmocnieniem prądowym, natomiast tranzystory polowe charakteryzują się niskim poborem mocy.

3.  **Przedstaw zasady działania podstawowych układów elektronicznych: wzmacniaczy, generatorów, filtrów.**
    Wzmacniacze to układy elektroniczne, które zwiększają amplitudę sygnału wejściowego. Generator to układ, który wytwarza sygnał o określonej częstotliwości. Filtry to układy, które pozwalają na przepuszczenie lub zatrzymanie sygnałów o określonej częstotliwości.

4.  **Przedstaw typy i zasady: modulacji i demodulacji.**
    Modulacja polega na zmianie parametrów sygnału nośnego w celu przeniesienia informacji. Demodulacja to proces odzyskiwania informacji z sygnału zmodulowanego. Przykłady modulacji to modulacja amplitudy (AM), modulacja częstotliwości (FM) i modulacja fazy (PM). Demodulacja odbywa się za pomocą prostownika lub detektora demodulacyjnego.

5.  **Podaj przykłady zastosowania przetworników A/C i C/A.**

    Przetworniki analogowo-cyfrowe (A/C) konwertują sygnały analogowe na cyfrowe, podczas gdy przetworniki cyfrowo-analogowe (C/A) konwertują sygnały cyfrowe na analogowe. Przykłady zastosowania przetworników A/C to odczytywanie sygnałów z czujników temperatury, napięcia i ciśnienia, natomiast przetworniki C/A są stosowane do syntezy sygnałów dźwiękowych w urządzen

6.  **Scharakteryzuj typy i przedstaw zasady działania bramek logicznych.**

    Bramki logiczne to układy elektroniczne, które wykonują operacje logiczne na sygnałach binarnych (0 lub 1). Wyróżnia się wiele typów bramek logicznych, takich jak bramki AND, OR, NOT, XOR, NAND i NOR. Bramki logiczne działają na zasadzie otwierania lub zamykania przepływu prądu w zależności od stanu wejść. Na przykład, bramka AND zwróci wartość 1 tylko wtedy, gdy oba jej wejścia są równocześnie ustawione na 1.

7.  **Porównaj: układ kombinacyjny i układ sekwencyjny.**

    Układ kombinacyjny to układ, w którym stan wyjść zależy tylko od stanów wejść. Oznacza to, że wyjście zależy tylko od bieżących wartości wejściowych, a nie od poprzednich wartości lub innych czynników. Przykładem układu kombinacyjnego jest dodawanie binarne. Układ sekwencyjny to układ, w którym stan wyjść zależy od poprzednich stanów wejść lub wyjść. Układy sekwencyjne są zdolne do przechowywania informacji, a ich stan wyjść może być zmieniany przez sygnały zegara lub przez wewnętrzny stan układu. Przykładem układu sekwencyjnego jest rejestr przesuwny.

8.  **Scharakteryzuj zasadę superpozycji w odniesieniu do obliczeń rozpływu prądów w obwodzie.**

    Zasada superpozycji w obwodach elektrycznych mówi, że wynikowy prąd lub napięcie w obwodzie może być obliczony jako suma prądów lub napięć wynikających z pojedynczych źródeł działających niezależnie od siebie. Oznacza to, że w obwodzie z kilkoma źródłami prądu lub napięcia, można analizować każde źródło niezależnie i sumować wyniki, aby uzyskać wynikowy prąd lub napięcie w obwodzie.

9.  **Przedstaw zastosowanie prawa Ohma i praw Kirchhoffa – w kontekście obliczania prądów i spadków napięć w obwodzie.**

    Prawo Ohma mówi, że prąd przepływający przez przewodnik jest wprost proporcjonalny do napięcia między jego końcami, przy stałej temperaturze i stałym oporze. Zgodnie z prawem Kirchhoffa, suma prądów w każdym węźle obwodu musi być równa zeru, a suma spadków napięć na każdej pętli obwodu musi być równa sumie źródeł napięcia w tej pętli. Te prawa są używane do obliczania prądów i spadków napięć w obwodzie. Na przykład, przy użyciu prawa Kirchhoffa, można obliczyć prąd w gałęzi obwodu lub napięcie między dwoma punktami obwodu, znając wartości źródeł napięcia i oporników.

10. **Podaj przykład wykorzystania twierdzenia o mocy maksymalnej w obwodzie.**

    Twierdzenie o mocy maksymalnej w obwodzie mówi, że moc pobierana przez obwód jest maksymalna, gdy impedancja obciążenia jest równa impedancji wewnętrznej źródła zasilającego. Wykorzystanie tego twierdzenia ma zastosowanie w projektowaniu układów elektronicznych, takich jak wzmacniacze lub filtry, w celu zapewnienia maksymalnej wydajności i minimalnej utraty mocy.

    Przykładowo, rozważmy układ wzmacniacza audio. W tym przypadku, źródłem sygnału jest generator sygnału audio, a obciążeniem jest głośnik. Aby uzyskać maksymalną moc przekazywaną do głośnika, impedancja głośnika powinna być zgodna z impedancją wewnętrzną wzmacniacza. Jeśli impedancja głośnika jest zbyt niska lub zbyt wysoka w stosunku do impedancji wewnętrznej wzmacniacza, to moc przekazywana do głośnika będzie mniejsza, a wzmacniacz będzie działał z mniejszą wydajnością. Dlatego dobór impedancji głośnika jest ważnym aspektem projektowania układów audio.

## ALGORYTMY I STRUKTURY DANYCH

1. **Czym powinien cechować się dobry algorytm?**

   Dobry algorytm powinien cechować się kilkoma cechami. Przede wszystkim powinien być poprawny, czyli dawać poprawne wyniki dla wszystkich przypadków testowych. Powinien być również efektywny pod względem czasu i pamięci, czyli działać w optymalnym czasie i korzystać z jak najmniejszej ilości pamięci. Powinien być łatwy do zrozumienia, czyli zrozumiały dla innych programistów, którzy mogą go później rozwijać lub modyfikować. Ponadto, dobry algorytm powinien być odporny na błędy danych, czyli radzić sobie z różnymi rodzajami danych wejściowych i zabezpieczać się przed sytuacjami, które mogą prowadzić do błędów.

1. **Scharakteryzuj podstawowe struktury algorytmów (algorytmy liniowe, algorytmy z rozgałęzieniami, algorytmy z powtórzeniami).**

   Podstawowe struktury algorytmów to algorytmy liniowe, algorytmy z rozgałęzieniami i algorytmy z powtórzeniami. Algorytmy liniowe wykonują sekwencyjnie kolejne instrukcje bez żadnych przerywania lub powtórzeń. Algorytmy z rozgałęzieniami wykonują różne instrukcje w zależności od warunków logicznych. Algorytmy z powtórzeniami wykonują instrukcje wiele razy, na podstawie warunków logicznych lub określonej liczby powtórzeń.

1. **Podaj przykład oszacowania złożoności obliczeniowej algorytmu.**

   Przykład oszacowania złożoności obliczeniowej algorytmu to złożoność czasowa algorytmu sortowania. Złożoność czasowa określa ilość czasu potrzebnego do wykonania algorytmu, zwykle mierzony w liczbie porównań lub przestawień elementów. Przykładowo, złożoność czasowa sortowania przez wstawianie wynosi O(n^2), co oznacza, że czas potrzebny do posortowania n elementów rośnie kwadratowo wraz ze wzrostem n.

1. **Metody projektowania algorytmów (rekurencja, „dziel i zwyciężaj”, metoda zachłanna, programowanie dynamiczne, algorytmy z powrotami) – działanie, zastosowania.**

   Metody projektowania algorytmów to rekurencja, „dziel i zwyciężaj”, metoda zachłanna, programowanie dynamiczne i algorytmy z powrotami. Rekurencja polega na wywoływaniu funkcji samej siebie, aż do osiągnięcia warunku stopu. Jest to przydatna technika w przypadku problemów, które mogą być podzielone na mniejsze podproblemy, które są rozwiązywane w sposób rekurencyjny.

   Metoda „dziel i zwyciężaj” polega na podziale problemu na mniejsze podproblemy, rozwiązywaniu ich oddzielnie, a następnie łączeniu wyników. Ta technika jest przydatna w przypadku problemów, które mogą być łatwiejsze do rozwiązania, gdy są podzielone na mniejsze części, np. sortowanie liczb lub obliczanie potęg.

   Metoda zachłanna polega na podejmowaniu decyzji w oparciu o lokalnie optymalne wybory, z nadzieją na znalezienie optymalnego rozwiązania. Ta technika jest przydatna w przypadku problemów, które wymagają podejmowania decyzji w oparciu o pewne kryteria, np. minimalizacja kosztów lub maksymalizacja zysków.

   Programowanie dynamiczne polega na rozwiązywaniu problemów poprzez kombinowanie wyników z podproblemów, które już zostały rozwiązane. Ta technika jest przydatna w przypadku problemów, które można podzielić na mniejsze, ale które wymagają rozwiązania wielokrotnie, np. problem plecakowy.

   Algorytmy z powrotami polegają na tworzeniu drzewa decyzyjnego, reprezentującego wszystkie możliwe kombinacje wyników, a następnie poszukiwaniu optymalnego rozwiązania przez nawigację po tym drzewie. Ta technika jest przydatna w przypadku problemów, które wymagają przejrzenia wszystkich możliwych kombinacji wyników, np. problem komiwojażera.

   Podsumowując, każda z tych technik projektowania algorytmów ma swoje zalety i ograniczenia, a wybór odpowiedniej zależy od konkretnego problemu do rozwiązania i jego wymagań.

1. **Porównaj podstawowe struktury danych (tablice, listy, kolejki, stosy, mapy, grafy, drzewa) – cechy, zastosowania.**'

   Podstawowe struktury danych to tablice, listy, kolejki, stosy, mapy, grafy i drzewa. Tablice są strukturami przechowującymi elementy uporządkowane w jednowymiarowym lub wielowymiarowym układzie. Listy są strukturami przechowującymi elementy w sposób dynamiczny, pozwalając na dodawanie i usuwanie elementów w dowolnym miejscu. Kolejki są strukturami przechowującymi elementy w kolejności, w jakiej zostały dodane, umożliwiając dostęp tylko do elementów na końcu kolejki. Stosy są strukturami przechowującymi elementy w kolejności LIFO (last in, first out), czyli ostatni element dodany jest pierwszy do usunięcia. Mapy są strukturami przechowującymi elementy w postaci pary klucz-wartość, umożliwiając dostęp do wartości na podstawie klucza. Grafy są strukturami przechowującymi węzły (wierzchołki) i krawędzie między nimi, pozwalając na modelowanie relacji między nimi. Drzewa są strukturami grafów, które zawierają węzły i krawędzie, ale mają wyraźną strukturę hierarchiczną, gdzie każdy węzeł ma dokładnie jednego rodzica.

   Zastosowania różnych struktur danych są zróżnicowane. Tablice i listy są często stosowane do przechowywania danych, np. wyników obliczeń. Kolejki i stosy są przydatne do przechowywania i przetwarzania danych, np. w systemach operacyjnych i algorytmach wyszukiwania. Mapy są wykorzystywane do przechowywania danych, takich jak słowniki i bazy danych. Grafy i drzewa są wykorzystywane w algorytmach grafowych, sieciach komputerowych i wizualizacjach danych.

   Podsumowując, każda struktura danych ma swoje cechy i zastosowania, a wybór odpowiedniej struktury danych jest kluczowy w projektowaniu efektywnych algorytmów.

## ARCHITEKTURA KOMPUTERÓW

1. **Porównaj konstrukcje modelu programowego procesora w podejściu CISC i RISC.**

   W podejściu CISC (Complex Instruction Set Computer) instrukcje procesora są złożone i zawierają wiele operacji. Procesory CISC mają wiele trybów adresowania, a ich instrukcje są długie i skomplikowane. W podejściu RISC (Reduced Instruction Set Computer) instrukcje procesora są proste i wykonywane w jednym cyklu zegara. Procesory RISC mają zwykle ograniczoną liczbę trybów adresowania, a ich instrukcje są krótkie i prostsze. Podejście RISC dąży do zwiększenia wydajności poprzez prostotę i optymalizację procesora.

1. **Omów podstawy realizacji systemu pamięci podręcznej uwzględniając jej poziomowość.**

   System pamięci podręcznej to hierarchiczny system pamięci, w którym dane są przechowywane w pamięciach o różnej szybkości i pojemności. Najbliżej procesora znajduje się pamięć podręczna (cache), która zawiera dane z często używanych obszarów pamięci. Pamięć podręczna jest zwykle podzielona na kilka poziomów, przy czym każdy kolejny poziom jest większy i wolniejszy od poprzedniego. Dane są automatycznie kopiowane z pamięci RAM do pamięci podręcznej, gdy są używane przez procesor. Poziomy pamięci podręcznej są projektowane w taki sposób, aby zapewnić maksymalną wydajność procesora i minimalizować liczbę dostępów do pamięci głównej.

1. **Zdefiniuj budowę modelu programowego jednostki centralnej – omów niezbędne rejestry, tryby adresowania, listę instrukcji oraz model operacji warunkowych.**

   Model programowy jednostki centralnej składa się z kilku rejestrow. Do najważniejszych należą rejestry ogólnego przeznaczenia, rejestry specjalne (np. rejestry stanu, liczniki instrukcji, rejestr błędów) oraz rejestry adresowe (np. rejestry bazowe, indeksowe). Tryby adresowania określają sposób adresowania danych i instrukcji, a lista instrukcji zawiera opis wszystkich dostępnych instrukcji procesora. Model operacji warunkowych określa, jak procesor wykonuje instrukcje warunkowe, takie jak skoki warunkowe, wykorzystując flagi stanu i rejestry specjalne.

1. **Omów architekturę przykładowego mikrokontrolera. Czym różni się mikrokontroler od mikroprocesora?**

   Mikrokontroler to specjalny rodzaj mikroprocesora, który ma wbudowane funkcje peryferyjne, takie jak przetworniki analogowo-cyfrowe, interfejsy komunikacyjne, zegary i timery. Mikrokontrolery są często stosowane w systemach wbudowanych, takich jak urządzenia elektroniczne, robotyka i automatyka. Różnica między mikrokontrolerem a mikroprocesorem polega na tym, że mikrokontroler ma wbudowane funkcje peryferyjne, co czyni go bardziej odpowiednim dla systemów wbudowanych.

1. **Przedstaw klasyfikację układów programowalnych. Krótko scharakteryzuj każdą z klas.**

   Układy programowalne można podzielić na trzy klasy: PAL (Programmable Array Logic), PLA (Programmable Logic Array) i FPGA (Field-Programmable Gate Array).
   PAL to układy programowalne, w których można zaprogramować tylko macierz AND, a macierz OR jest stała. PAL umożliwia projektowanie układów logicznych, ale jest stosunkowo mało elastyczny.

   PLA to układy programowalne, w których można zaprogramować zarówno macierz AND, jak i macierz OR. PLA jest bardziej elastyczny niż PAL i umożliwia projektowanie bardziej skomplikowanych układów logicznych.

   FPGA to układy programowalne, w których programowalna jest każda bramka logiczna. FPGA umożliwia projektowanie bardzo skomplikowanych układów logicznych, które można dostosować do konkretnych wymagań aplikacji. FPGA są często stosowane w systemach wbudowanych, gdzie wymagane jest bardzo szybkie i elastyczne przetwarzanie sygnałów.

1. **Na czym polega minimalizacja funkcji logicznych.**
   Minimalizacja funkcji logicznych polega na uproszczeniu złożonych funkcji logicznych poprzez zastąpienie ich bardziej prostymi funkcjami. Minimalizacja funkcji logicznych jest przydatna w projektowaniu układów cyfrowych, ponieważ umożliwia zmniejszenie liczby elementów i zwiększenie ich wydajności.

1. **Omów podstawowe rodzaje przerzutników. Wyjaśnij zasadę działania przerzutnika typu: D, T, JK.**
   Przerzutnik to element cyfrowy, który przechowuje jeden bit informacji. Przerzutniki dzielą się na asynchroniczne i synchroniczne. Przerzutnik asynchroniczny reaguje na zmiany sygnału wejściowego niezależnie od sygnału zegarowego. Przerzutnik synchroniczny reaguje na zmiany sygnału wejściowego tylko w określonym momencie, zwykle przy zboczu rosnącym lub opadającym sygnału zegarowego.

   Przerzutnik D to przerzutnik z jednym wejściem danych i jednym sygnałem zegarowym. Przerzutnik T to przerzutnik z jednym wejściem, który zmienia stan wyjściowy na przeciwny przy każdym zboczu sygnału zegarowego. Przerzutnik JK to przerzutnik z dwoma wejściami, które służą do ustawienia stanu początkowego. Przerzutnik JK pozwala na zmianę stanu wyjściowego w oparciu o sygnał zegarowy i wejście J oraz K.

## BAZY DANYCH

1. **Jakie są różnice pomiędzy SQL, MySQL oraz SQL Server?**

   SQL (Structured Query Language) to język służący do zarządzania i manipulowania danymi w bazach danych. MySQL to otwarte oprogramowanie bazodanowe oparte na języku SQL i używane zwykle w połączeniu z aplikacjami internetowymi. SQL Server to system zarządzania relacyjnymi bazami danych firmy Microsoft. Różnica między MySQL a SQL Server polega na tym, że MySQL jest darmowy i otwarty, podczas gdy SQL Server jest oprogramowaniem komercyjnym i płatnym. SQL Server oferuje także większe możliwości w zakresie skalowalności i bezpieczeństwa.

1. **Charakterystyka procesu projektowania bazy danych.**

   Projektowanie bazy danych to proces tworzenia struktury bazy danych, określenia relacji między tabelami, a także definiowania atrybutów, kluczy i ograniczeń. Proces ten obejmuje również modelowanie relacji między tabelami, projektowanie schematu bazy danych, określanie wymagań dotyczących funkcjonalności i wydajności oraz implementację bazy danych.

1. **Przetwarzanie informacji w bazach danych. Porównaj metody oraz zastosowanie.**

   Przetwarzanie informacji w bazach danych obejmuje m.in. wyszukiwanie, sortowanie, filtrowanie i agregację danych. Metody przetwarzania danych obejmują zapytania SQL, procedury składowane, widoki, raporty i kwerendy. Każda z metod ma swoje zastosowanie, np. zapytania SQL są używane do przeszukiwania i pobierania danych z bazy danych, a procedury składowane są używane do wykonywania operacji na danych.

1. **Porównaj typy baza danych i system zarządzania bazą danych.**

   Typy baz danych obejmują relacyjne, hierarchiczne, sieciowe i obiektowe. Systemy zarządzania bazą danych (DBMS) to oprogramowanie, które umożliwia zarządzanie bazami danych. Różnice między systemami zarządzania bazą danych obejmują skalowalność, wydajność, bezpieczeństwo i koszty.

1. **Jakie są typy bazy danych, jaki wybrałbyś do np. małego sklepu internetowego, dużego portalu społecznościowego.**

   Typy bazy danych to m.in. relacyjne, obiektowe, hierarchiczne i sieciowe. W małym sklepie internetowym najlepiej nadaje się baza danych relacyjna, która umożliwia przechowywanie informacji o produktach, klientach i zamówieniach. W przypadku dużego portalu społecznościowego najlepiej nadają się bazy danych NoSQL, które umożliwiają skalowanie poziome i obsługę dużej liczby użytkowników.

1. **Do czego wykorzystujemy relacyjne bazy danych, a do czego noSQL?**

   Relacyjne bazy danych są używane do przechowywania i zarządzania danymi w postaci tabel, natomiast bazy danych NoSQL są używane do przechowywania i zarządzania dużymi i złożonymi zbiorami danych, które nie pasują do tradycyjnego modelu relacyjnego.

1. **Optymalizacja zapytań do baz danych – podaj podstawowe metody na przykładzie.**

   Optymalizacja zapytań do baz danych obejmuje m.in. indeksowanie, optymalizację zapytań, użycie zapytań przygotowanych, użycie kwerend przechowywanych, partycjonowanie tabel i wykorzystanie cachowania. Indeksowanie polega na utworzeniu indeksów na kolumnach w tabeli, co umożliwia szybsze wyszukiwanie i sortowanie danych. Optymalizacja zapytań polega na analizie i poprawie zapytań SQL, tak aby były wydajniejsze. Kwerendy przechowywane to zapytania, które są zapisane w bazie danych i mogą być wykorzystywane wielokrotnie. Partycjonowanie tabel polega na podzieleniu tabeli na mniejsze części, co umożliwia szybsze wyszukiwanie danych. Cachowanie to przechowywanie wyników zapytań w pamięci podręcznej, co umożliwia szybsze odczytywanie danych.

1. **W jakim celu stosowane są wyzwalacze w bazach danych – podaj przykłady.**

   Wyzwalacze w bazach danych to specjalne procedury, które uruchamiają się automatycznie w odpowiedzi na określone zdarzenia, np. dodanie, zmiana lub usunięcie rekordu z tabeli. Wyzwalacze są używane do automatyzacji określonych operacji w bazie danych, takich jak logowanie zmian, aktualizacja zależnych rekordów lub wykonywanie określonych działań w przypadku wystąpienia określonego zdarzenia. Przykłady wyzwalaczy to wyświetlanie komunikatów, dodawanie rekordów lub zmiana statusu rekordu.

1. **Współczesne bazy danych w odniesieniu do modelu relacyjnego.**

   Współczesne bazy danych często stosują model hybrydowy, który łączy cechy modelu relacyjnego i NoSQL. Model hybrydowy umożliwia przechowywanie dużej ilości danych w elastyczny sposób, co umożliwia łatwe skalowanie i dostosowanie do potrzeb aplikacji.

1. **Agregacja danych – gdzie ją lepiej zrobić po stronie serwera, czy użytkownika końcowego, podaj przykład**

   Agregacja danych to proces łączenia i przetwarzania danych w celu uzyskania wyników w postaci np. sumy, średniej, minimalnej lub maksymalnej wartości. Agregacja danych lepiej powinna być wykonana po stronie serwera, ponieważ umożliwia to przetwarzanie dużych ilości danych z dużą wydajnością i minimalnym obciążeniem dla klienta. Przykładem może być agregacja danych w sklepie internetowym, gdzie liczone są sumy i średnie wartości zamówień dla całej bazy danych lub dla poszczególnych klientów.

## INŻYNIERIA OPROGRAMOWANIA

1. **Wskaż w jakich fazach procesu wytwórczego oprogramowania przeprowadza się walidację i weryfikację statyczną, a w jakich walidację i weryfikację dynamiczną. Z jakimi dokładnie produktami jest to związane?**

   Walidacja i weryfikacja statyczna są przeprowadzane na produktach w fazie wczesnego etapu procesu wytwórczego, takich jak dokumenty specyfikacji wymagań i projektowe. Walidacja statyczna polega na ocenie poprawności i kompletności produktów, a weryfikacja statyczna na ocenie zgodności z normami i standardami. Walidacja i weryfikacja dynamiczna są przeprowadzane na produktach w fazie późniejszego etapu procesu wytwórczego, takich jak kod i testy. Walidacja dynamiczna polega na ocenie, czy produkt spełnia wymagania użytkowników, a weryfikacja dynamiczna na ocenie zgodności z dokumentacją projektową i wymaganiami.

1. **Przedstaw uwarunkowania trójkąta inżynierii oprogramowania oraz wskaż w jaki sposób możemy w projekcie minimalizować ryzyka (w postaci zagrożeń) związane z jego atrybutami.**

   Trójkąt inżynierii oprogramowania obejmuje trzy atrybuty: czas, koszt i jakość. Minimalizowanie ryzyka związane z tymi atrybutami można osiągnąć poprzez stosowanie metodyki Agile, w której priorytetem jest dostarczenie działającego produktu, w ciągłym dialogu z klientem i szybkim reagowaniu na zmiany. W Agile często stosuje się techniki takie jak refaktoryzacja, testowanie jednostkowe, ciągła integracja, w celu minimalizacji ryzyka i poprawy jakości kodu.

1. **Posługując się praktycznym przykładem wyjaśnij na czym polega planowanie adaptacyjne. Jaki model cyklu życia oprogramowania wspiera planowanie tego typu?**

1. **Czy w przypadku zastosowania planowania predykcyjnego możemy zastosować kaskadowy model zarządzania cyklem wytwarzania oprogramowania? Uzasadnij swoją odpowiedź posługując się praktycznym przykładem.**

   W przypadku planowania predykcyjnego, w którym wszystkie etapy projektu są ściśle określone, trudno jest zastosować kaskadowy model zarządzania cyklem wytwarzania oprogramowania, ponieważ zmiany w projekcie są trudne do wprowadzenia. Przykładem może być projektowanie systemu medycznego, gdzie wymagania są ściśle określone i nie ma miejsca na zmiany.

1. **Jakie uwarunkowania projektu powinna obejmować analiza na poziomie wymagań biznesowych, a jakie na poziomie wymagań użytkowników i poziomie wymagań funkcjonalnych?**

   Analiza na poziomie wymagań biznesowych powinna obejmować uwarunkowania biznesowe, takie jak cele biznesowe, rynek, konkurencję i inne. Analiza na poziomie wymagań użytkowników powinna obejmować potrzeby użytkowników, oczekiwania i preferencje, a analiza na poziomie wymagań funkcjonalnych powinna obejmować specyfikację funkcjonalną produktu.

1. **Na co dokładnie mają wpływ w projekcie programistycznym wymagania pozafunkcjonalne opisujące usługi lub charakterystyki wydajnościowe produktu programistycznego?**

   Wymagania pozafunkcjonalne opisują usługi lub charakterystyki wydajnościowe produktu programistycznego, takie jak szybkość, wydajność, niezawodność, bezpieczeństwo, łatwość konserwacji, skalowalność, dostępność i inne. Mają one wpływ na projektowanie systemu i wybór technologii.

1. **Czym się różnią wymagania systemowe od wymagań funkcjonalnych i wymagań determinowanych przez interfejsy zewnętrzne dla projektowanego oprogramowania?**

   Wymagania systemowe dotyczą cech i ograniczeń systemu, takich jak dostępność, niezawodność, wydajność, bezpieczeństwo i skalowalność, podczas gdy wymagania funkcjonalne dotyczą funkcjonalności systemu, takiej jak jego zachowanie w odpowiedzi na określone wejście. Wymagania determinowane przez interfejsy zewnętrzne odnoszą się do interakcji systemu z innymi systemami lub aplikacjami.

1. **Przedstaw istotne różnice pomiędzy strategią pozyskiwania wymagań zorientowaną na użycie a strategią pozyskiwania wymagań zorientowaną na produkt.**

   Strategia pozyskiwania wymagań zorientowana na użycie koncentruje się na zrozumieniu, w jaki sposób użytkownicy korzystają z produktu, podczas gdy strategia pozyskiwania wymagań zorientowana na produkt skupia się na definiowaniu cech i funkcjonalności produktu. Ważne jest, aby stosować obie strategie w celu uzyskania pełnego obrazu wymagań produktu.

1. **Wymień co najmniej trzy główne aktywności zarządzania wymaganiami dla produktu programistycznego, które nie przyczynią się do powstania konieczności wprowadzania zmian w projekcie.**

   Trzy główne aktywności zarządzania wymaganiami to planowanie wymagań, analiza wymagań i śledzenie wymagań. Planowanie wymagań obejmuje określenie strategii pozyskiwania wymagań, zakresu i priorytetów. Analiza wymagań polega na zrozumieniu i precyzyjnym sformułowaniu wymagań. Śledzenie wymagań dotyczy monitorowania zmian w wymaganiach i ich weryfikacji w celu zapewnienia zgodności z dokumentacją projektową.

1. **Jaka istotna cecha modelu spiralnego wyróżnia go w odniesieniu do każdego innego modelu zarządzania cyklem wytwarzania oprogramowania?**

   Wyróżniającą cechą modelu spiralnego jest to, że jest to model iteracyjny, w którym każda iteracja obejmuje planowanie, projektowanie, budowanie i testowanie. Jest to model cyklu życia oprogramowania, który pozwala na stopniowe doskonalenie produktu w oparciu o informacje uzyskane na każdym etapie. Odróżnia go to od innych modeli, takich jak model kaskadowy, gdzie każda faza projektu jest oddzielona i poprzedzająca kolejną.

1. **Jaka jest największa wada zastosowania modelu ewolucyjnego w procesie wytwarzania oprogramowania?**

   Największą wadą zastosowania modelu ewolucyjnego jest jego brak struktury i nieprzewidywalność, co może prowadzić do nieoczekiwanych problemów i opóźnień w procesie wytwarzania oprogramowania. Ponadto, ze względu na to, że model ten polega na ciągłym dopracowywaniu produktu, koszty projektu mogą być trudne do oszacowania i kontrolowania.

1. **Które perspektywy modelu „4+1” opisują wewnętrzną strukturę tworzonego oprogramowania na różnych poziomach abstrakcji i szczegółowości?**

   Model "4+1" składa się z pięciu perspektyw, z których cztery dotyczą różnych aspektów architektury systemu: perspektywa logiczna, perspektywa procesowa, perspektywa fizyczna oraz perspektywa wdrożenia. Piąta perspektywa, perspektywa przypadków użycia, opisuje interakcje między użytkownikami a systemem.

1. **Omów jakie atrybuty zewnętrzne oraz jakie atrybuty wewnętrzne powinny zostać zawsze zdefiniowane metrycznie (określone ilościowo) w przypadku specyfikacji, jakie w przypadku kodu źródłowego, a jakie dla danych testowych.**

   Atrybuty zewnętrzne, takie jak wydajność i niezawodność, powinny być zdefiniowane metrycznie w specyfikacji, podczas gdy atrybuty wewnętrzne, takie jak jakość kodu, powinny być zdefiniowane metrycznie w kodzie źródłowym. Atrybuty danych testowych, takie jak poprawność i kompletność, również powinny być zdefiniowane metrycznie.

1. **W jaki sposób możemy poprawnie oszacować opłacalność projektu informatycznego?**

   Opłacalność projektu informatycznego można oszacować poprzez porównanie kosztów z zyskami, czyli opłacalnością projektu. W skrócie, opłacalność projektu jest to stosunek zysków do kosztów.

1. **Jaka jest relacja pomiędzy kosztem a opłacalnością projektu programistycznego?**

   Koszt projektu programistycznego jest jednym z czynników wpływających na jego opłacalność. Im niższy koszt, tym większa szansa na uzyskanie wyższej opłacalności. Jednakże, koszt nie jest jedynym czynnikiem wpływającym na opłacalność projektu.

1. **Co należy uwzględnić w procesie estymacji nakładu pracy dla danego przedsięwzięcia programistycznego? Na co rzutuje ten atrybut procesu w projekcie?**

   W procesie estymacji nakładu pracy dla danego przedsięwzięcia programistycznego należy uwzględnić wiele czynników, takich jak liczba członków zespołu, poziom skomplikowania projektu, wymagania funkcjonalne i niefunkcjonalne, dostępność zasobów, harmonogram prac i inne. Rzutuje to na dokładność oszacowania nakładu pracy i czasu trwania projektu.

1. **W związku z tym, że w każdym projekcie programistycznym estymacji podlega wiele atrybutów procesu i produktów rozwoju oprogramowania, wyjaśnij w jaki sposób możemy ocenić sprawdzalność wybranych metod estymacji i procesu i produktu.**

   Aby ocenić sprawdzalność wybranych metod estymacji i procesu i produktu, można wykorzystać techniki analizy ryzyka i testowanie. Przykładowo, podejście zwinne umożliwia częste testowanie produktu i dokonywanie korekt w celu zwiększenia jego jakości i zapewnienia zgodności z wymaganiami.

1. **Wyjaśnij w jaki sposób możemy dokonać oceny ryzyka dla realizowanego przedsięwzięcia programistycznego.**

   Ocena ryzyka w projekcie programistycznym polega na identyfikacji, analizie, ocenie i zarządzaniu ryzykiem w celu minimalizacji negatywnych skutków, jakie mogą pojawić się w trakcie realizacji projektu. Aby dokonać oceny ryzyka, należy dokładnie przeanalizować projekt, zidentyfikować potencjalne problemy, które mogą wpłynąć na powodzenie projektu, sporządzić listę możliwych ryzyk oraz dokładnie przebadać każde zidentyfikowane ryzyko pod kątem jego wpływu na projekt i prawdopodobieństwa wystąpienia. Następnie ocenia się ryzyko na podstawie prawdopodobieństwa i wpływu, a także podejmuje się odpowiednie działania, aby zminimalizować ryzyko. W procesie oceny ryzyka ważne jest również określenie krytycznych obszarów projektu, które wymagają szczególnej uwagi i przygotowania planu awaryjnego w razie wystąpienia problemów.

1. **Jakie możliwe działania można podjąć odnośnie ryzyka typu szansa, a jakie odnośnie ryzyka typu zagrożenie w projekcie programistycznym?**

   W przypadku ryzyka typu szansa, czyli nieoczekiwanej korzyści, możemy podjąć działania, które pomogą nam ją wykorzystać w projekcie programistycznym. Możemy zwiększyć nakład pracy w określonym obszarze, by jak najlepiej wykorzystać szansę, a także zmodyfikować cele projektu, by zawrzeć w nich wykorzystanie możliwej korzyści. W przypadku ryzyka typu zagrożenie, możemy podjąć działania zmierzające do zminimalizowania skutków tego zagrożenia. Na przykład, w przypadku zagrożenia opóźnieniem w dostawie sprzętu, możemy zwiększyć nakład pracy w innych obszarach projektu, by zrekompensować opóźnienie.

1. **Jaka jeszcze inna perspektywa oprócz perspektywy specyfikacyjnej i implementacyjnej dotyczy modelowania rozwiązania z wykorzystaniem języka UML? Na czym ona polega?**

   Jedną z innych perspektyw w modelowaniu rozwiązania z wykorzystaniem języka UML jest perspektywa wdrażania. W tej perspektywie projektujemy i modelujemy rozwiązanie w kontekście jego implementacji i wdrażania. Skupiamy się na aspektach technicznych związanych z instalacją, konfiguracją i wdrożeniem rozwiązania. Dzięki temu możemy w łatwy sposób przewidzieć i rozwiązać problemy związane z procesem wdrożenia oraz zoptymalizować proces implementacji. Perspektywa wdrażania jest szczególnie przydatna w projektach programistycznych, gdzie często występuje potrzeba integracji z istniejącymi systemami i infrastrukturą.

## SZTUCZNA INTELIGENCJA

1. **Podaj rzeczywiste przykłady zastosowania metod sztucznej inteligencji**

   - systemy rekomendacyjne w serwisach internetowych, np. Netflix czy Amazon,
   - rozpoznawanie obrazów w medycynie, np. wykrywanie chorób na zdjęciach rentgenowskich,
   - autonomiczne pojazdy, np. samochody bez kierowcy,
   - chatboty i asystenci głosowi, np. Siri czy Google Assistant,
   - systemy przetwarzania języka naturalnego, np. tłumaczenie maszynowe.

1. **Omów budowę sztucznych sieci neuronowych. Czym się różni sieć neuronowa w architekturze płytkiej od głębokiej.**

   Sztuczne sieci neuronowe składają się z neuronów, które otrzymują sygnały wejściowe, przetwarzają je i przekazują sygnały wyjściowe. Sieci te składają się z warstw, w których neurony są połączone w określony sposób. Sieć neuronowa w architekturze płytkiej ma tylko jedną warstwę ukrytą, natomiast sieć neuronowa w architekturze głębokiej składa się z wielu warstw ukrytych. Dzięki temu sieci głębokie są w stanie lepiej modelować złożone zależności między danymi wejściowymi a wyjściowymi.

1. **Czy jest predykcja. W jakim celu się ja stosuje?**

   Predykcja polega na przewidywaniu wartości wyjściowych na podstawie danych wejściowych. Stosuje się ją w celu przewidywania np. zachowań użytkowników, trendów rynkowych, wyników sportowych, czy też diagnozowania chorób na podstawie symptomów.

1. **Gdzie stosujemy uczenie nadzorowane, a gdzie nienadzorowane – opisz oraz wymień typy znanego oprogramowania**

   Uczenie nadzorowane stosujemy wtedy, gdy mamy dostęp do danych treningowych, w których znamy zarówno dane wejściowe, jak i poprawne wartości wyjściowe. Dzięki temu sieć neuronowa może "uczyć się" na tych danych i nauczyć się przewidywania poprawnych wartości wyjściowych. Przykładem oprogramowania wykorzystującego uczenie nadzorowane jest TensorFlow. Uczenie nienadzorowane stosujemy wtedy, gdy mamy tylko dane wejściowe i chcemy na ich podstawie wykryć jakieś wzorce. Przykładem oprogramowania wykorzystującego uczenie nienadzorowane jest klastrowanie.

1. **Jaka jest różnica między klasyfikacją a regresją – oraz gdzie są wykorzystywane, podaj znane ci rozwiązania.**

   Klasyfikacja polega na przypisywaniu danych wejściowych do określonych klas lub kategorii. Regresja polega na przewidywaniu wartości liczbowych wyjściowych na podstawie danych wejściowych. Przykładem zastosowania klasyfikacji jest system antyspamowy, który przypisuje maile do kategorii spam lub nie-spam. Przykładem zastosowania regresji jest system przewidujący ceny nieruchomości na podstawie danych o ich cechach.

1. **Podaj wady i zalety rozwiązań opartych o sztuczną inteligencję w znanych ci rozwiązaniach.**

   - Zalety

     - Automatyzacja i usprawnienie procesów biznesowych, co pozwala na oszczędność czasu i kosztów.
     - Zwiększenie efektywności i jakości pracy w wielu dziedzinach, na przykład w przemyśle, medycynie czy logistyce.
     - Możliwość analizy i interpretacji dużych zbiorów danych, co pozwala na wyciąganie wartościowych wniosków i podejmowanie lepszych decyzji.
     - Możliwość tworzenia inteligentnych asystentów w różnych dziedzinach, takich jak np. wirtualne asystenty głosowe czy chatboty.

   - Wady
     - Wysokie koszty wdrożenia i utrzymania, związane z koniecznością posiadania odpowiedniej infrastruktury oraz specjalistycznej wiedzy i umiejętności programistycznych.
     - Niepewność i trudność w przewidywaniu skutków działań podejmowanych przez sztuczną inteligencję.
     - Zagrożenie dla prywatności i bezpieczeństwa danych, gdyż wrażliwe informacje mogą trafić w niepowołane ręce lub być wykorzystane w sposób niezgodny z intencjami.
     - Ryzyko zastąpienia ludzi przez maszyny w niektórych dziedzinach pracy, co może prowadzić do bezrobocia lub braku kreatywności w rozwiązywaniu problemów.

   Przykłady rozwiązań opartych o sztuczną inteligencję to np. chatboty, systemy rekomendacyjne, rozpoznawanie mowy czy obrazów, systemy detekcji oszustw, automatyka przemysłowa, inteligentne systemy energetyczne czy rolnicze.

1. **Co to jest walidacja? Jakie znasz metody walidacji?**

   Walidacja to proces potwierdzania, czy produkt, system lub usługa spełnia określone wymagania i spełnia oczekiwania użytkowników lub klientów. W kontekście oprogramowania, walidacja odnosi się do potwierdzenia, że produkt lub system działa zgodnie z określonymi wymaganiami biznesowymi i spełnia oczekiwania użytkowników.

   Metody walidacji obejmują:

   - Testy funkcjonalne: obejmują testowanie funkcjonalności systemu w celu potwierdzenia, że działa ona zgodnie z wymaganiami biznesowymi i oczekiwaniami użytkowników.
   - Testy integracyjne: obejmują testowanie interakcji między różnymi komponentami systemu w celu upewnienia się, że funkcjonują one razem poprawnie.
   - Testy akceptacyjne: obejmują testowanie systemu w celu potwierdzenia, że spełnia on określone wymagania biznesowe i jest gotowy do użycia przez użytkowników.
   - Testy wydajnościowe: obejmują testowanie wydajności systemu w celu potwierdzenia, że działa on zgodnie z oczekiwaniami pod względem szybkości, skalowalności i dostępności.
   - Testy bezpieczeństwa: obejmują testowanie systemu w celu potwierdzenia, że jest on bezpieczny i chroni dane użytkowników przed nieuprawnionym dostępem.

   Metody te mogą być stosowane w różnych kombinacjach, w zależności od rodzaju systemu i wymagań biznesowych. Walidacja jest ważnym etapem w procesie rozwoju oprogramowania, ponieważ pozwala upewnić się, że produkt lub system działa zgodnie z oczekiwaniami użytkowników i spełnia wymagania biznesowe.

## BEZPIECZEŃSTWO INFORMACJI

1. **Wymień i porównaj szyfry podstawieniowe i przestawieniowe.**

   Szyfry podstawieniowe i przestawieniowe są dwoma podstawowymi rodzajami szyfrów stosowanych do szyfrowania tekstu jawnego. Szyfry podstawieniowe polegają na zamianie każdego znaku lub grupy znaków z tekstu jawnego na inny znak lub grupę znaków, zgodnie z ustalonym kluczem szyfrującym. Szyfry przestawieniowe natomiast polegają na przestawieniu kolejności występowania znaków lub grup znaków w tekście jawnym, również zgodnie z ustalonym kluczem. Porównując oba rodzaje szyfrów, można stwierdzić, że szyfry podstawieniowe są łatwiejsze do złamania, ponieważ mają stałe odwzorowanie między tekstem jawnym a szyfrogramem, co ułatwia analizę statystyczną. Z kolei szyfry przestawieniowe są trudniejsze do złamania, ponieważ znaki są przestawiane, a nie zastępowane, co utrudnia analizę statystyczną.

1. **Wymień i porównaj szyfry symetryczne i asymetryczne.**

   Szyfry symetryczne i asymetryczne to dwa podstawowe rodzaje szyfrów stosowanych w kryptografii. Szyfry symetryczne polegają na wykorzystaniu tego samego klucza do szyfrowania i deszyfrowania tekstu, co oznacza, że klucz musi być znany zarówno nadawcy, jak i odbiorcy. Szyfry asymetryczne, zwane także kluczowymi, wykorzystują dwa różne klucze do szyfrowania i deszyfrowania tekstu. Klucz publiczny jest używany do szyfrowania tekstu, a klucz prywatny do jego deszyfrowania. Zaletą szyfrów symetrycznych jest ich szybkość i efektywność, jednakże wymaga to bezpiecznego udostępnienia klucza między nadawcą a odbiorcą. Szyfry asymetryczne są bezpieczniejsze, ponieważ klucz prywatny jest znany tylko odbiorcy, ale są mniej efektywne i wolniejsze w działaniu.

1. **Wykonujesz testy penetracyjne – przedstaw charakterystykę poszczególnych etapów.**

   Testy penetracyjne (ang. penetration testing) to proces, w którym specjaliści od bezpieczeństwa komputerowego symulują ataki na systemy, aplikacje i infrastrukturę sieciową w celu identyfikacji i eliminacji podatności. Istnieją różne etapy testów penetracyjnych, które obejmują:

   - Planowanie i przygotowanie: W tym etapie określane są cele testów penetracyjnych, analizowany jest zasięg testów oraz opracowywana jest strategia testów. W ramach planowania i przygotowania powinno się również określić, jakie narzędzia i techniki testowe będą wykorzystane oraz ustalić zespół odpowiedzialny za przeprowadzenie testów.
   - Skanowanie: Etap skanowania polega na przeskanowaniu sieci w poszukiwaniu aktywnych urządzeń i usług, które mogą być atakowane. W tym etapie wykorzystywane są narzędzia do skanowania sieci, takie jak np. nmap.
   - Identifikacja podatności: W tym etapie specjaliści od bezpieczeństwa komputerowego poszukują podatności w systemie lub aplikacji, które mogą być wykorzystane przez potencjalnych atakujących. W celu identyfikacji podatności wykorzystuje się narzędzia, takie jak np. Nessus.
   - Atak: W tym etapie specjaliści od bezpieczeństwa komputerowego próbują przeprowadzić atak na system lub aplikację, wykorzystując znalezione podatności. Atak może mieć różną formę, od ataku typu DoS (Denial of Service) po wykorzystanie exploitów do zdalnego wykonania kodu.
   - Ocena ryzyka: W tym etapie oceniana jest powaga potencjalnych zagrożeń dla systemu lub aplikacji, które zostały zidentyfikowane w poprzednich etapach testów penetracyjnych. Ocena ryzyka pozwala na określenie priorytetów w zakresie działań naprawczych oraz planowanie działań poprawczych.
   - Raportowanie: W ostatnim etapie specjaliści od bezpieczeństwa komputerowego sporządzają raport zawierający wyniki testów penetracyjnych, w tym opisane podatności, ocenę ryzyka oraz zalecenia dotyczące działań poprawczych.

   Ważne jest, aby testy penetracyjne były przeprowadzane przez wykwalifikowany personel, który posiada odpowiednie doświadczenie w zakresie bezpieczeństwa komputerowego.

1. **Ataki Dos/DDoS – scharakteryzuj rodzaje i metody przeprowadzania ataku.**

   Atak DoS (Denial of Service) to rodzaj ataku, którego celem jest uniemożliwienie normalnego korzystania z usług, aplikacji lub zasobów sieciowych. Atak DDoS (Distributed Denial of Service) to zaawansowana forma ataku DoS, która wykorzystuje wiele komputerów, aby zwiększyć moc ataku i utrudnić jego wykrycie.

   Rodzaje ataków DoS:

   - Ataki na protokoły: atakują bezpośrednio protokoły sieciowe, takie jak TCP/IP lub DNS, aby uniemożliwić użytkownikom dostęp do serwerów.
   - Ataki wysyłania dużych pakietów: polegają na wysyłaniu dużych pakietów danych do serwera, co powoduje przeciążenie jego zasobów i utrudnia lub uniemożliwia korzystanie z usług.
   - Ataki na aplikacje: wykorzystują słabości lub luki w aplikacjach sieciowych, takich jak serwery WWW, aby zwiększyć obciążenie serwera lub wywołać awarię.
   - Ataki rozproszone: DDoS wykorzystuje zdecentralizowane zasoby, takie jak botnety, które są kontrolowane przez atakującego, aby zwiększyć siłę ataku i utrudnić jego wykrycie.

   Metody przeprowadzania ataku DoS/DDoS:

   - Ataki SYN flood: wykorzystują luki w protokole TCP/IP, wysyłając duże ilości pakietów SYN do serwera, aby uniemożliwić normalne połączenia.
   - Ataki DNS amplification: wykorzystują serwery DNS jako pośredników, aby zwiększyć moc ataku i utrudnić jego wykrycie.
   - Ataki ping flood: wysyłają duże ilości pakietów ping do serwera, aby zwiększyć obciążenie i utrudnić lub uniemożliwić korzystanie z usług.
   - Ataki botnet: wykorzystują zdecentralizowane zasoby, takie jak botnety, aby zwiększyć moc ataku i utrudnić jego wykrycie.
   - Ataki aplikacji: wykorzystują słabości lub luki w aplikacjach sieciowych, takich jak serwery WWW, aby zwiększyć obciążenie serwera lub wywołać awarię.

   Aby zabezpieczyć się przed atakami DoS/DDoS, należy stosować metody zabezpieczeń, takie jak firewalle, systemy wykrywania i zapobiegania atakom (IPS), sieci prywatne VPN, oprogramowanie antywirusowe i antyspamowe, a także regularne aktualizacje systemu i oprogramowania.

1. **Omów zasadę przeprowadzania ataków Man in the middle (MITM), jak się przed tym chronić.**

   Atak Man in the Middle (MITM) polega na przechwyceniu komunikacji między dwoma urządzeniami przez atakującego, który podszywa się pod jedno z tych urządzeń. W ten sposób atakujący może wykradać poufne informacje lub manipulować przesyłanymi danymi.

   Metoda ataku MITM polega na przekierowaniu ruchu sieciowego przez urządzenie atakującego, tak aby przechwycić dane przesyłane pomiędzy dwoma innymi urządzeniami. Najczęściej stosowanymi metodami ataku są:

   - ARP Spoofing – atakujący zmienia tablice ARP w celu przekierowania ruchu sieciowego do swojego urządzenia.
   - DNS Spoofing – atakujący fałszuje rekordy DNS, aby przekierować ruch do innej strony.
   - SSL Stripping – atakujący usuwa szyfrowanie SSL z połączenia między dwoma urządzeniami, co pozwala na przechwycenie informacji przesyłanych w sieci.

   Aby chronić się przed atakami MITM, można zastosować kilka metod:

   - Używanie szyfrowanych połączeń, takich jak HTTPS, SSH, SSL, czy VPN, które utrudniają przechwycenie i odczytanie przesyłanych informacji.
   - Używanie protokołów autoryzacyjnych, takich jak EAP, WPA2, czy 802.1x, które wymagają uwierzytelnienia użytkownika przed nawiązaniem połączenia.
   - Sprawdzanie certyfikatów SSL, aby upewnić się, że są one ważne i pochodzą od zaufanego źródła.
   - Używanie narzędzi, takich jak antywirusy, firewalle, IDS/IPS, które mogą wykryć i zablokować próby ataku MITM.
   - Utrzymywanie oprogramowania i systemów w aktualnej wersji, co pozwoli na wykorzystanie najnowszych zabezpieczeń i poprawek związanych z atakami MITM.

1. **Wymień i scharakteryzuj wybrane narzędzia pentestera.**

   Pentesterzy używają różnych narzędzi do testowania penetracyjnego, aby zidentyfikować potencjalne luki w zabezpieczeniach systemów informatycznych. Poniżej przedstawiam charakterystykę kilku popularnych narzędzi pentestera:

   - Nmap - Narzędzie służące do skanowania sieci w celu identyfikacji otwartych portów i usług. Pozwala na wykrycie systemów podatnych na ataki.
   - Metasploit - Narzędzie do wykrywania podatności i eksploatacji systemów. Metasploit zawiera wiele exploitów i payloadów, które mogą być wykorzystane do zdalnego dostępu do systemu.
   - Wireshark - Narzędzie służące do analizy ruchu sieciowego. Pozwala na przechwytywanie i analizowanie pakietów sieciowych, co może pomóc w identyfikacji podatności systemów.
   - John the Ripper - Narzędzie do łamania haseł. Pozwala na ataki słownikowe i brute force na hasła.
   - John the Ripper - Narzędzie do łamania haseł. Pozwala na ataki słownikowe i brute force na hasła.
   - Aircrack-ng - Narzędzie służące do łamania haseł sieci Wi-Fi. Pozwala na przechwytywanie pakietów sieciowych i ataki słownikowe na hasła.
   - Hydra - Narzędzie służące do ataków bruteforce na różne protokoły uwierzytelnienia, takie jak SSH, FTP czy HTTP
   - sqlmap - Narzędzie służące do testowania penetracyjnego baz danych. Pozwala na wykrywanie podatności i testowanie zabezpieczeń baz danych.

   Narzędzia te mogą być wykorzystywane do przeprowadzania testów penetracyjnych w celu zidentyfikowania potencjalnych luki w zabezpieczeniach systemów informatycznych. Ważne jest, aby używać ich wyłącznie do celów etycznych i zgodnych z prawem.

1. **Omów na przykładach wybrane ataki socjotechniczne.**

   Ataki socjotechniczne to rodzaj ataków, które wykorzystują ludzką naiwność, brak uwagi, zaufanie lub nieświadomość, aby osiągnąć cel. Przykłady takich ataków to:

   Phishing - atak polegający na podszywaniu się pod zaufane instytucje, takie jak banki, instytucje rządowe czy portale społecznościowe, w celu pozyskania poufnych informacji, takich jak hasła lub numery kart kredytowych. Atakujący wysyła wiadomości e-mail lub SMS-y z linkami do fałszywych stron internetowych, które wyglądają jak prawdziwe.

   Spoofing - atak polegający na fałszowaniu adresów IP lub innych identyfikatorów, aby oszukać systemy informatyczne lub użytkowników końcowych. Przykładem może być spoofing e-maili, w którym osoba podszywa się pod kogoś innego, aby uzyskać dostęp do poufnych informacji.

   Pretekstowanie - atak polegający na udawaniu osoby lub instytucji w celu uzyskania poufnych informacji. Przykładem jest osoba dzwoniąca do pracownika banku i udająca się za klienta, aby uzyskać dostęp do informacji o jego koncie.

   Atak typu "przypnij ogon osła" - atak polegający na wykorzystaniu niskiego poziomu bezpieczeństwa w jednym elemencie systemu informatycznego, aby uzyskać dostęp do innych. Przykładem może być wykorzystanie słabego hasła jednego użytkownika, aby uzyskać dostęp do całego systemu.

   Atak "dumpster diving" - atak polegający na przeszukiwaniu koszy na śmieci, aby uzyskać poufne informacje, takie jak dokumenty, dyski twarde czy karty kredytowe. Atakujący może wykorzystać takie informacje do celów szantażu, wyłudzeń lub kradzieży tożsamości.

   Aby chronić się przed atakami socjotechnicznymi, ważne jest zwracanie uwagi na podejrzane wiadomości e-mail, SMS-y lub rozmowy telefoniczne. Należy również stosować silne hasła i nie udostępniać poufnych informacji osobom, których nie znamy lub którym nie ufa się w pełni. Warto również szkolić pracowników w zakresie bezpieczeństwa informatycznego i regularnie przeprowadzać audyty w celu wykrycia ewentualnych luk w systemach zabezpieczeń.

1. **Omów zasadę działania oraz porównaj systemy IDS oraz IPS.**

   Systemy IDS (Intrusion Detection System) i IPS (Intrusion Prevention System) są stosowane do wykrywania i zapobiegania nieautoryzowanemu dostępowi do systemów komputerowych i sieci. Oba systemy działają na podobnej zasadzie, ale różnią się sposobem reakcji na wykryte zagrożenia.

   IDS to system, który monitoruje ruch sieciowy i rejestruje wszelkie podejrzane zdarzenia, takie jak próby ataku lub nieautoryzowanego dostępu. IDS wykorzystuje różne metody, takie jak analiza sygnatur, anomalie ruchu, heurystyka i wiele innych, aby wykryć potencjalne zagrożenia. Po wykryciu nieprawidłowości IDS generuje alert, który może zostać przekazany administratorowi systemu w celu dalszej analizy i podejmowania odpowiednich działań.

   IPS to system, który dodatkowo do funkcji IDS posiada możliwość blokowania nieautoryzowanego ruchu w czasie rzeczywistym. IPS analizuje ruch sieciowy i, w przypadku wykrycia potencjalnego zagrożenia, blokuje ten ruch na poziomie sieci, aby uniemożliwić dalsze działania atakującemu. IPS jest bardziej skuteczny niż IDS, ponieważ umożliwia szybką reakcję na atak i minimalizuje szkody, jakie może wyrządzić atakujący.

   W porównaniu do sieci IDS, IPS jest bardziej kosztowny i skomplikowany w implementacji. Jednakże, w przypadku krytycznych sieci i infrastruktury, zastosowanie IPS jest niezbędne. IDS może być stosowany w mniejszych sieciach i środowiskach, gdzie szybka reakcja na atak nie jest tak krytyczna.

   W skrócie, IDS i IPS są obydwa ważnymi narzędziami w ochronie sieci i systemów komputerowych przed atakami. IDS jest skutecznym narzędziem do wykrywania zagrożeń i generowania alertów, podczas gdy IPS umożliwia blokowanie ruchu sieciowego w czasie rzeczywistym i szybką reakcję na atakującego.

1. **Czy jest możliwość bycia anonimowym w Internecie?**

   Możliwe jest utrzymanie pewnego stopnia anonimowości w Internecie, ale całkowita anonimowość jest trudna lub niemożliwa do osiągnięcia. W sieci zawsze pozostawiamy ślady, takie jak adresy IP, cookies, logi serwera itp., które mogą być wykorzystane do identyfikacji naszej osoby lub pochodzenia ruchu internetowego.

   Jednak istnieją sposoby na zwiększenie poziomu anonimowości w Internecie. Można korzystać z serwerów proxy, sieci Tor lub VPN, które zmieniają nasz adres IP i ukrywają pochodzenie naszego ruchu. Możemy również używać pseudonimów lub kont e-mailowych, które nie zawierają naszych prawdziwych danych personalnych.

   Należy jednak pamiętać, że nawet przy użyciu tych narzędzi, nigdy nie ma pewności, że pozostajemy w pełni anonimowi w Internecie, a nasze działania w sieci mogą być nadal monitorowane i śledzone przez rządy, organizacje czy hakerów.

## PROGRAMOWANIE

1. **W jaki sposób identyfikujemy miejsce przekazania sterowania w inne miejsce w programie w językach interpretowanych, a w jaki w językach kompilowanych?**

1. **Wskaż różnice pomiędzy programowaniem imperatywnym a programowaniem funkcyjnym. Które podejście związane jest ze zmianą stanu?**

1. **Czym jest postać strukturalna kodu źródłowego i co należy zrobić aby można było ją otrzymać w przypadku kiedy mamy do czynienia nawet z programowaniem funkcyjnym?**

1. **Wskaż sprawdzalną metodę zapewniania skalowalności kodu źródłowego tworzonego z zastosowaniem paradygmatu programowania obiektowego.**

1. **Które składowe klasy są najważniejsze i dlaczego?**

1. **Który mechanizm paradygmatu programowania obiektowego jest najważniejszy i dlaczego?**

1. **Jaka jest istotna różnica pomiędzy programowaniem klasowym a programowaniem prototypowym?**

1. **Co jeszcze oprócz funkcji i metod możemy określić jako abstrakcję przy tworzeniu oprogramowania z wykorzystaniem programowania zorientowanego obiektowo?**

1. **Omów mechanizm polimorfizmu w zakresie możliwości wykorzystania szablonów.**

1. **Wyjaśnij na czym polega polimorfizm w zakresie możliwości wykorzystania mechanizmu przeciążania operatorów.**

1. **Jaka jest znacząca różnica pomiędzy metaprogramowaniem a tworzeniem kodu źródłowego z wykorzystaniem podejścia generycznego?**

1. **Omów struktury kontrolne przy pomocy których możliwe jest zbudowanie dowolnego programu. Podaj praktyczne przykłady każdego wskazanego typu struktury.**

1. **Co w praktyce oznacza, że kod źródłowy programu spełnia warunek deterministyczności?**

1. **Omów typy i przypadki zastosowania znanych Ci modyfikatorów parametrów metod języków obiektowych takich jak C++,  Java i C#.**

1. **W jaki sposób możemy zdefiniować metodę synchroniczną w kodzie źródłowym i na czym ona polega?**

1. **Podaj praktyczny przykład obsługi wyjątku kontrolowanego i wyjątku niekontrolowanego. Kiedy możemy stosować wyjątki kontrolowane?**

1. **W jaki sposób możemy sterować procesem serializacji obiektów w tworzonym oprogramowaniu?**

1. **Omów uwarunkowania dostępu do składowych prywatnych obiektu przy zastosowaniu mechanizmu odzwierciedleń (refleksji).**

1. **Odwołując się do znanego Ci języka programowania obiektowego wskaż problemy związane z wykorzystywaniem kolekcji przechowujących obiekty.**

1. **W jaki sposób w kodzie źródłowym należy odzwierciedlić brak modyfikatora metod, który jest widoczny w diagramie klas UML?**

## TECHNOLOGIE INTERNETOWE I MOBILNE

1. **Opisz jak przebiega komunikacja komputera z serwerem HTTP podczas próby odczytu pliku \*.php 2. Omów budowę i zasadę działania formularza HTML5 oraz przedstaw przynajmniej trzy typy pól.**

1. **Omów różnice między metodami przesyłania danych GET i POST. Podaj przykłady zastosowań obu metod.**

1. **Omów na przykładach budowę i sposoby wykorzystania kaskadowych arkuszy stylów CSS.**

1. **Technologia Ajax – czym jest i w jakich rozwiązaniach jest wykorzystywana**

1. **Omów zasadę komunikacji aplikacji klienckiej z serwerem bazodanowym na przykładzie PHP i MySQL**

1. **Przedstaw sposób wykorzystania mechanizmu plików cookies.**

1. **Przedstaw sposób wykorzystania mechanizmu zmiennych sesyjnych**

1. **Omów podstawowe konstrukcje i znaczenie języka XML**

1. **Scharakteryzuj możliwości języka HTML5 umożliwiające wygodne tworzenie aplikacji graficznych.**

1. **Wymień po jednym przykładzie stosowanego na stronach WWW skryptowego języka programowania, wykonywanego a) po stronie klienta b) po stronie serwera.**

## INTERNET RZECZY, SIECI KOMPUTEROWE

1. **W jaki sposób zbudować prostą sieć do małego biura.**

   Prosta sieć dla małego biura może składać się z kilku elementów, takich jak:

   - Router - urządzenie, które pozwala na łączenie się z Internetem oraz przesyłanie danych między urządzeniami w sieci lokalnej. Router może mieć wbudowany switch, który pozwala na podłączenie wielu urządzeń.
   - Switch - urządzenie, które pozwala na łączenie ze sobą wielu urządzeń w sieci lokalnej. Switch przesyła dane między urządzeniami w sieci na podstawie adresów MAC.
   - Kable sieciowe - potrzebne do połączenia urządzeń z routerem lub switchem. Można wykorzystać kable Ethernet kategorii 5e lub 6.
   - Urządzenia końcowe - urządzenia, które korzystają z sieci, takie jak komputery, drukarki, telefony itp.

   W celu zbudowania prostej sieci do małego biura należy postępować zgodnie z poniższymi krokami:

   - Podłącz router do Internetu przy użyciu kabla Ethernet.
   - Podłącz switch do routera przy użyciu kabla Ethernet.
   - Podłącz urządzenia końcowe do switcha przy użyciu kabli Ethernet.
   - Skonfiguruj router, aby uzyskał dostęp do Internetu i zapewnił dostęp do sieci lokalnej.
   - Skonfiguruj urządzenia końcowe, aby korzystały z sieci lokalnej, np. poprzez przypisanie adresów IP.
   - Uruchom oprogramowanie antywirusowe i firewall, aby chronić sieć przed atakami.
   - Przetestuj sieć, aby upewnić się, że wszystko działa poprawnie.

   Prosta sieć z jednym routerem i switchem powinna być wystarczająca dla małego biura. Jednak w przypadku większej liczby urządzeń lub większej przepustowości sieci, można zastosować dodatkowe switch'e lub rozwiązania takie jak sieci VLAN.

1. **W jakich sytuacjach wskazane byłoby zastosowanie medium: kable miedziane/światłowód/transmisja bezprzewodowa.**

   Wybór medium transmisyjnego w sieci komputerowej zależy od wielu czynników, w tym od kosztów, wymagań dotyczących prędkości transmisji, odległości, trwałości, niezawodności i dostępności.

   Kable miedziane (np. Ethernet) są często stosowane w sieciach LAN, zwłaszcza gdy wymagana jest dobra jakość transmisji przy niskich kosztach. Zalety kabli miedzianych to: niska cena, łatwość instalacji, duża dostępność, łatwość diagnostyki i napraw, a także relatywnie niska opóźnienia i duże prędkości transmisji danych. Wadami mogą być ograniczona odległość transmisji i podatność na zakłócenia elektromagnetyczne.

   Światłowody są z kolei bardziej kosztowne i trudniejsze w instalacji niż kable miedziane, ale oferują wyższą jakość transmisji, większą odległość przesyłu i większą odporność na zakłócenia elektromagnetyczne. Światłowody są często stosowane w sieciach długodystansowych, takich jak sieci WAN i sieci dostępowe do Internetu.

   Transmisja bezprzewodowa, z kolei, jest często stosowana w sytuacjach, gdy nie ma możliwości fizycznej instalacji kabli lub gdy wymagana jest mobilność. Bezprzewodowe sieci LAN (np. Wi-Fi) są powszechnie stosowane w biurach, sklepach i innych miejscach publicznych. Bezprzewodowa transmisja może być także stosowana do łączenia urządzeń w sieciach IoT, w systemach bezpieczeństwa i w transmisji multimediów. Wadami bezprzewodowej transmisji mogą być mniejsza przepustowość, podatność na zakłócenia i ryzyko zagrożeń bezpieczeństwa.

1. **Jakie problemy pojawiają się z adresacją IPv4.**

   Adresacja IPv4, która jest najpowszechniej stosowana w sieciach komputerowych, posiada kilka problemów:

   - Brak wystarczającej liczby adresów IP: adresy IPv4 składają się z 32-bitowego ciągu cyfr, co daje maksymalnie 4,3 miliarda unikalnych adresów. W obecnych czasach, kiedy każde urządzenie podłączone do Internetu potrzebuje unikalnego adresu IP, ta liczba okazuje się niewystarczająca.
   - Skomplikowana administracja adresami IP: przydział adresów IP, ich zarządzanie i konfiguracja są skomplikowane i wymagają dużo pracy i wiedzy technicznej. Może to prowadzić do błędów, które powodują problemy w sieci.
   - Nieelastyczna struktura adresacji: adresy IPv4 są podzielone na dwie części - adres sieciowy i adres hosta - co ogranicza elastyczność i skalowalność adresacji IP.
   - Bezpieczeństwo: adresacja IPv4 nie zapewnia wystarczającego poziomu bezpieczeństwa, co staje się coraz bardziej krytyczne w obliczu rosnącej liczby ataków hakerskich.

1. **Co jest potrzebne do wdrożenia IPv6 w sieci LAN.**

   Wdrożenie protokołu IPv6 w sieci LAN wymaga kilku kluczowych czynników.

   Po pierwsze, router musi obsługiwać IPv6 i być skonfigurowany do przesyłania ruchu IPv6 w sieci.

   Po drugie, urządzenia końcowe, takie jak komputery i urządzenia mobilne, muszą obsługiwać IPv6 i mieć skonfigurowane odpowiednie adresy IPv6.

   Po trzecie, administrator sieci musi przeprowadzić migrację z systemu adresacji IPv4 na IPv6, co może wymagać zmiany oprogramowania sieciowego, takiego jak serwery DNS, DHCP i firewalle.

   Wdrożenie IPv6 może również wymagać zaktualizowania istniejącej infrastruktury sieciowej, takiej jak przełączniki i routery, aby obsługiwały nowy protokół.

1. **Jakie problemy występują w użytkowaniu i zarządzaniu sieciami Wi-Fi.**

   W użytkowaniu i zarządzaniu sieciami Wi-Fi mogą występować różne problemy, takie jak:

   - Słaby sygnał: Słaby sygnał może powodować problemy z prędkością połączenia lub powodować, że połączenie jest niestabilne.
   - Interferencja: Interferencja elektromagnetyczna może powodować zakłócenia sygnału, co prowadzi do spadku prędkości lub utraty połączenia.
   - Bezpieczeństwo: Sieci Wi-Fi są bardziej podatne na ataki z zewnątrz niż sieci przewodowe, dlatego ważne jest, aby zapewnić odpowiednie zabezpieczenia sieci.
   - Nadmierne obciążenie sieci: W przypadku, gdy zbyt wiele urządzeń korzysta z sieci, może to prowadzić do nadmiernego obciążenia i spadku prędkości połączenia.
   - Zarządzanie urządzeniami: W przypadku większych sieci może być trudne zarządzanie wszystkimi urządzeniami, co może prowadzić do problemów z utrzymaniem sieci w dobrym stanie.
   - Kompatybilność: Niektóre starsze urządzenia nie są w stanie obsługiwać najnowszych standardów Wi-Fi, co prowadzi do problemów z połączeniem.
   - Wpływ na zdrowie: Istnieją kontrowersje dotyczące wpływu fal elektromagnetycznych na zdrowie człowieka, dlatego ważne jest, aby stosować się do odpowiednich norm i zasad dotyczących bezpieczeństwa.

1. **Jak zabezpieczyć urządzenia sieciowe przed zagrożeniami.**

   Aby zabezpieczyć urządzenia sieciowe przed zagrożeniami, należy zastosować odpowiednie środki bezpieczeństwa. Poniżej przedstawiam kilka podstawowych zasad:

   - Regularne aktualizacje - należy systematycznie aktualizować oprogramowanie urządzeń sieciowych, aby wyeliminować znane luki w zabezpieczeniach.
   - Zmiana domyślnych haseł - domyślne hasła są łatwe do odgadnięcia, dlatego zawsze powinno się zmienić domyślne hasła i korzystać z silnych haseł.
   - Zastosowanie firewalla - firewall (zapora sieciowa) może zablokować nieautoryzowany dostęp do sieci.
   - Włączenie szyfrowania - zawsze należy korzystać z protokołów szyfrowania (np. WPA2) i unikać korzystania z niezabezpieczonych sieci.
   - Kontrola dostępu - należy stosować kontrole dostępu, aby ograniczyć dostęp do urządzeń i sieci tylko do uprawnionych użytkowników.
   - Regularne szkolenia - użytkownicy sieci powinni być regularnie szkoleni w zakresie bezpieczeństwa, aby uniknąć popełniania błędów i zwiększyć świadomość związana z zagrożeniami sieciowymi.
   - Audyt bezpieczeństwa - regularne przeprowadzanie audytów bezpieczeństwa pozwoli na wykrycie ewentualnych luk w zabezpieczeniach i podjęcie odpowiednich działań naprawczych.

   Te i inne środki bezpieczeństwa pomogą zabezpieczyć urządzenia sieciowe przed zagrożeniami.

1. **Jak wykorzystać sieci VLAN w sieciach korporacyjnych.**

   Sieci VLAN (Virtual LAN) są stosowane w celu podzielenia jednej sieci fizycznej na wiele wirtualnych sieci, które pozwalają na izolację ruchu i zwiększenie bezpieczeństwa w sieciach korporacyjnych. Przykładowe sposoby wykorzystania sieci VLAN w sieciach korporacyjnych to:

   - Izolacja grup użytkowników: Użytkownicy w tej samej sieci fizycznej mogą być podzieleni na różne grupy, a każda grupa może mieć własne reguły dostępu do zasobów sieciowych. Na przykład, grupa sprzedaży może mieć dostęp tylko do wybranych zasobów, podczas gdy grupa IT może mieć dostęp do wszystkich zasobów.

   - Uproszczone zarządzanie: Sieci VLAN umożliwiają łatwiejsze zarządzanie siecią i zmniejszenie liczby urządzeń sieciowych, które trzeba konfigurować. Dzięki VLAN-om można np. zgrupować użytkowników w różnych częściach budynku, bez konieczności podłączania dodatkowych kabli.

   - Ochrona przed atakami sieciowymi: Sieci VLAN pozwalają na izolację ruchu w sieci i zapobiegają rozprzestrzenianiu się ataków sieciowych. Można także stosować urządzenia sieciowe, takie jak firewalle, do kontrolowania ruchu między różnymi sieciami VLAN.

   - Uproszczony monitoring ruchu sieciowego: Sieci VLAN pozwalają na monitorowanie ruchu sieciowego w poszczególnych grupach użytkowników, dzięki czemu można łatwiej wykryć i zlokalizować potencjalne problemy z siecią.

   Aby wykorzystać sieci VLAN w sieciach korporacyjnych, należy najpierw skonfigurować przełącznik sieciowy zgodnie z zasadami VLAN, a następnie podzielić użytkowników na grupy i przypisać każdą grupę do odpowiedniej sieci VLAN. Warto pamiętać, że konfiguracja sieci VLAN wymaga odpowiedniej wiedzy technicznej i doświadczenia w zarządzaniu sieciami komputerowymi.

1. **W jaki sposób zapewnić wysoką niezawodność sieci LAN.**

   Aby zapewnić wysoką niezawodność sieci LAN, można podjąć kilka działań, takich jak:

   - Zapewnienie redundantnych połączeń: W sieci LAN można stosować kilka połączeń pomiędzy urządzeniami, co zapewni niezawodność sieci w przypadku awarii jednego z połączeń.
   - Zastosowanie protokołów zapewniających redundancję: Dostępne są protokoły, takie jak Spanning Tree Protocol (STP), które umożliwiają wykrywanie pętli w sieci, a następnie blokują je, co zapobiega awariom.
   - Regularne aktualizacje oprogramowania: Regularne aktualizacje oprogramowania urządzeń sieciowych (takich jak routery, przełączniki) zapewniają poprawę wydajności, a także poprawki związane z bezpieczeństwem.
   - Monitoring i zarządzanie siecią: Wdrożenie systemu monitoringu i zarządzania siecią pozwala na szybkie wykrywanie i rozwiązywanie problemów, co minimalizuje czas przestoju sieci.
   - Ochrona przed atakami: Wdrożenie odpowiednich rozwiązań bezpieczeństwa, takich jak zapory ogniowe i systemy wykrywania intruzów, pozwala na ochronę sieci przed atakami, co zwiększa jej niezawodność.
   - Redundancyjne zasilanie: Zapewnienie redundancji w zasilaniu urządzeń sieciowych (takich jak serwery, przełączniki) za pomocą zasilaczy awaryjnych lub generatorów zapewnia ciągłość działania sieci w przypadku awarii zasilania.

   Wprowadzenie tych działań pozwala na zapewnienie wysokiej niezawodności sieci LAN i minimalizację czasu przestoju sieci.

1. **Jak ograniczyć ataki na sieci LAN.**

   Aby ograniczyć ataki na sieci LAN, można podjąć kilka działań:

   - Zastosowanie firewalla - zapobiega to dostępowi do sieci z nieautoryzowanych źródeł oraz przepływowi niechcianego ruchu sieciowego.
   - Zmiana domyślnych haseł na urządzeniach sieciowych - wiele ataków na sieci LAN wykorzystuje domyślne hasła do urządzeń sieciowych. Zmiana tych haseł zwiększa bezpieczeństwo sieci.
   - Zastosowanie protokołu VPN - zapobiega to atakom typu "man in the middle" oraz umożliwia zdalny dostęp do zasobów sieciowych, jednocześnie zapewniając bezpieczną transmisję danych.
   - Zastosowanie autoryzacji użytkowników - umożliwia to kontrolowanie dostępu do zasobów sieciowych, co ogranicza ryzyko ataków.
   - Aktualizacja oprogramowania i firmware - zapewnia to poprawę bezpieczeństwa sieci poprzez usuwanie znanych błędów i luk w zabezpieczeniach.
   - Szkolenie pracowników - edukacja pracowników w zakresie bezpieczeństwa sieciowego oraz wymuszanie stosowania polityk bezpieczeństwa zwiększa świadomość i umożliwia szybsze reagowanie na potencjalne zagrożenia.

1. **Kiedy routing statyczny ma przewagę nad routingiem dynamicznym.**

   Routing statyczny i dynamiczny to dwa różne sposoby konfiguracji routingu w sieciach komputerowych. Routing statyczny polega na ręcznym wprowadzeniu statycznych wpisów routingu do tablic routingu na routerach, podczas gdy routing dynamiczny polega na automatycznym uaktualnianiu tablic routingu przez protokoły routingu takie jak OSPF, RIP czy BGP.

   Routing statyczny może mieć przewagę nad routingiem dynamicznym w następujących sytuacjach:

   - Małe sieci o prostych topologiach, w których ręczna konfiguracja jest łatwa i nie wymaga dużo czasu.
   - W przypadku, gdy mamy kilka routerów połączonych ze sobą i ruch w sieci jest niewielki, routing statyczny może być bardziej efektywny niż dynamiczny.
   - W sieciach, w których zmienna jest mała, a sieć jest stabilna i nie ulega częstym zmianom, routing statyczny może być wystarczający i łatwiejszy do zarządzania.

   Routing dynamiczny ma jednak zwykle przewagę nad statycznym w większych sieciach i w przypadku sieci o bardziej złożonej topologii, gdzie zmienność sieci i ruchu jest większa. Routing dynamiczny automatycznie dostosowuje się do zmian w sieci, takich jak awarie sprzętu, a także umożliwia równoważenie obciążenia w sieci.

1. **Jakie narzędzia stosuje się do rozwiązywania problemów w sieci.**

   Do rozwiązywania problemów w sieciach stosuje się różne narzędzia, w tym:

   - Narzędzia monitorujące sieć, takie jak Wireshark, tcpdump, Nagios, Zabbix czy Cacti, które pozwalają na śledzenie ruchu sieciowego i wykrywanie problemów w czasie rzeczywistym.
   - Narzędzia diagnostyczne, takie jak ping, traceroute, nslookup czy ipconfig, które pozwalają na identyfikację problemów związanych z łącznością sieciową.
   - Narzędzia do zarządzania siecią, takie jak OpenNMS, SolarWinds, czy PRTG Network Monitor, które pozwalają na zdalne zarządzanie i monitorowanie sieci.
   - Narzędzia do konfiguracji sieci, takie jak PuTTY czy SecureCRT, które pozwalają na zdalne połączenie z urządzeniami sieciowymi i konfigurację ich ustawień.
   - Narzędzia do automatyzacji konfiguracji, takie jak Ansible czy Puppet, które pozwalają na automatyzację i zarządzanie konfiguracją urządzeń sieciowych.

   Każde narzędzie ma swoje specyficzne zastosowanie i poziom zaawansowania, ale ich skuteczne wykorzystanie może znacznie ułatwić i przyspieszyć proces rozwiązywania problemów w sieciach.

1. **Jakie znaczenie ma zgodność rozwiązania ze standardem.**

   Zgodność rozwiązania ze standardem ma duże znaczenie w przypadku sieci komputerowych, ponieważ umożliwia ona interoperacyjność między różnymi urządzeniami oraz zapewnia spójność i stabilność działania sieci. Standardy są określone przez organizacje takie jak IEEE (Institute of Electrical and Electronics Engineers) czy IETF (Internet Engineering Task Force) i określają one wymagania techniczne, protokoły i procedury, które muszą być spełnione przez urządzenia i oprogramowanie sieciowe, aby zapewnić zgodność ze standardem. Przestrzeganie standardów pozwala na uniknięcie problemów związanych z kompatybilnością i zapewnia spójność działania sieci.

1. **W jaki sposób dobrać technologię dostępu do Internetu.**

   Dobór technologii dostępu do Internetu zależy przede wszystkim od lokalizacji, wymagań użytkowników oraz warunków środowiskowych. Poniżej przedstawiam kilka popularnych technologii dostępu do Internetu:

   - DSL (Digital Subscriber Line) - technologia pozwalająca na przesyłanie danych za pomocą linii telefonicznej. DSL oferuje szybkości od kilku do kilkudziesięciu Mbps i jest zwykle dostępny w miejskich obszarach.
   - Kablowy Internet - technologia polegająca na przesyłaniu danych za pomocą sieci kablowej. Oferta kablowego Internetu jest zwykle dostępna w większych miastach i oferuje szybkości od kilkudziesięciu do kilkuset Mbps.
   - Technologie bezprzewodowe - w tym wypadku mamy do wyboru kilka technologii, takich jak Wi-Fi, LTE czy 5G. Bezprzewodowe technologie są coraz popularniejsze i umożliwiają dostęp do Internetu praktycznie w każdym miejscu.
   - Satelitarny Internet - technologia polegająca na przesyłaniu danych za pomocą satelitów. Satelitarny Internet jest dostępny praktycznie w każdym miejscu na Ziemi, ale jest zwykle wolniejszy i droższy niż inne technologie.

1. **Jak zapewnić właściwy przeszył danych głosowych w sieci.**

   Aby zapewnić właściwy przesył danych głosowych w sieci, należy zwrócić uwagę na kilka kluczowych czynników:

   - Szerokość pasma - Sieci VoIP wymagają znacznie mniejszej przepustowości niż tradycyjne połączenia telefoniczne. Jednak w przypadku zbyt małej przepustowości, jakość rozmowy może znacznie ucierpieć. Dlatego ważne jest, aby zapewnić odpowiednią szerokość pasma dla ruchu VoIP.
   - Latency (opóźnienie) - Opóźnienie to czas, który upływa od wysłania sygnału głosowego przez jednego rozmówcę do otrzymania go przez drugiego rozmówcę. Opóźnienie może wpłynąć na jakość rozmowy, dlatego ważne jest, aby ograniczyć jego wartość do minimum.
   - Jitter - Jitter to nieregularne opóźnienia między pakietami danych, które składają się na rozmowę. Może on powodować zakłócenia i pogorszenie jakości rozmowy.
   - QoS (Quality of Service) - QoS to zestaw zasad i mechanizmów służących do zapewnienia odpowiedniej jakości ruchu sieciowego w czasie rzeczywistym. Umożliwia ono zapewnienie priorytetowego przepływu ruchu VoIP w przypadku dużego obciążenia sieci.

   Aby zapewnić właściwy przesył danych głosowych w sieci, należy wykorzystać odpowiednie protokoły i kodeki (np. G.711, G.729), a także zainstalować odpowiednie urządzenia sieciowe (np. routery, przełączniki, bramy VoIP) i skonfigurować je w sposób optymalny dla sieci VoIP.

1. **W jaki sposób ograniczyć dostęp do wybranych hostów lub usług.**

   Ograniczenie dostępu do wybranych hostów lub usług można osiągnąć poprzez zastosowanie mechanizmu filtracji pakietów na poziomie sieci lub transportu. Istnieją różne sposoby implementacji takiego ograniczenia, w tym:

   - Używanie list kontrolnych dostępu (ACL) - umożliwiają one określenie adresów źródłowych i docelowych, portów oraz protokołów, które mają być blokowane lub zezwolone. ACL są zazwyczaj wykorzystywane na urządzeniach sieciowych, takich jak routery, przełączniki i zapory ogniowe.
   - Wirtualne sieci prywatne (VPN) - pozwalają na utworzenie bezpiecznego połączenia między dwoma urządzeniami za pośrednictwem publicznej sieci, takiej jak Internet. Dzięki VPN można ograniczyć dostęp do określonych zasobów lub usług tylko dla użytkowników, którzy są w stanie połączyć się z siecią VPN.
   - Firewall - zapora ogniowa to specjalny rodzaj oprogramowania lub sprzętu, który monitoruje ruch sieciowy i blokuje niepożądane połączenia lub ruch sieciowy.
   - Serwer proxy - działa jako pośrednik między komputerem użytkownika a internetem. Użytkownik wysyła żądanie do serwera proxy, a serwer przekazuje je do docelowego serwera. Serwer proxy może być skonfigurowany tak, aby blokować żądania lub przekierowywać je do innych serwerów.
   - Wybór odpowiedniego narzędzia zależy od potrzeb i wymagań sieci oraz poziomu bezpieczeństwa, który chcemy osiągnąć.

1. **Czym rożni się Arduino od Raspberry Pi.**

   Arduino i Raspberry Pi to dwie popularne platformy dla projektantów elektroniki, programistów i entuzjastów technologii. Oba urządzenia są komputerami jednopłytkowymi, ale różnią się przede wszystkim w swoim przeznaczeniu i specyfikacji.

   Arduino to platforma projektowa, która została zaprojektowana z myślą o sterowaniu różnymi urządzeniami elektronicznymi. Jest idealnym narzędziem dla projektantów, którzy chcą tworzyć różnego rodzaju urządzenia, takie jak inteligentne systemy domowe, roboty, kontrolery, itp. Arduino jest wyposażone w mikrokontroler, który umożliwia programowanie w języku C/C++. Platforma ta jest idealna dla osób, które potrzebują niskopoziomowego dostępu do urządzeń elektronicznych, takich jak czujniki, diody LED, silniki, itp.

   Raspberry Pi to bardziej wszechstronna platforma, zaprojektowana z myślą o użytkowaniu ogólnym, takim jak przeglądanie internetu, oglądanie filmów, granie w gry, programowanie itp. Jest to komputer jednopłytkowy, który działa pod kontrolą systemu operacyjnego, takiego jak Linux. Raspberry Pi jest wyposażone w procesor ARM, pamięć RAM, porty USB, porty HDMI, port Ethernet oraz port GPIO (General Purpose Input/Output), który umożliwia podłączenie różnych urządzeń elektronicznych.

   Podsumowując, Arduino jest platformą projektową, która umożliwia programowanie i kontrolowanie różnych urządzeń elektronicznych, natomiast Raspberry Pi jest komputerem jednopłytkowym, który można wykorzystać do różnych zastosowań, takich jak programowanie, przeglądanie internetu, granie w gry i wiele innych.

1. **Jakie języki programowania używane są w technologiach IoT.**

   W technologiach IoT używa się różnych języków programowania, w zależności od zastosowania i specyfiki projektu. Poniżej przedstawiam kilka najczęściej stosowanych języków:

   - C/C++ - to języki, które cechują się szybkością i niskim zużyciem zasobów, co jest szczególnie ważne w przypadku urządzeń z ograniczonymi zasobami. C/C++ są wykorzystywane do programowania mikrokontrolerów i platform typu Arduino.
   - ython - to język interpretowany, który cechuje się dużą elastycznością i łatwością w tworzeniu prototypów. Python jest często używany do tworzenia aplikacji internetowych, baz danych, a także sterowników urządzeń.
   - Java - to język, który jest często stosowany w projektach IoT, w których wymagana jest duża skalowalność i elastyczność. Java jest często wykorzystywana w systemach sterowania i zarządzania, a także w aplikacjach mobilnych.
   - JavaScript - to język, który jest używany w aplikacjach internetowych, a także w aplikacjach mobilnych. JavaScript umożliwia interakcję z urządzeniami i odczytywanie danych z czujników.
   - Lua - to język, który jest stosowany w urządzeniach z ograniczonymi zasobami, takich jak routery, modemy, a także platformy typu Arduino.
   - Swift - to język, który jest stosowany w aplikacjach mobilnych dla systemu iOS. Swift umożliwia tworzenie aplikacji, które korzystają z danych z czujników i urządzeń IoT.

   Oprócz wymienionych powyżej języków, w IoT stosowane są także inne języki programowania, takie jak Ruby, Go czy Kotlin.

1. **Jakie komponenty będą potrzebne do zbudowania systemu inteligentnego domu.**

   System inteligentnego domu to system, który umożliwia zdalne zarządzanie różnymi urządzeniami w domu za pomocą smartfona lub tabletu. W zależności od potrzeb i preferencji, do budowy takiego systemu mogą być wykorzystane różne komponenty, jednak niektóre z nich są niezbędne. Poniżej przedstawiam listę podstawowych elementów, które będą potrzebne do zbudowania systemu inteligentnego domu:

   - Kontroler inteligentny - to główny element systemu, który kontroluje działanie poszczególnych urządzeń i pozwala na ich zdalne sterowanie.
   - Urządzenia peryferyjne - to urządzenia, które będą kontrolowane przez system inteligentny. Mogą to być m.in. oświetlenie, termostat, system alarmowy, drzwi i brama wjazdowa, system audio i wideo oraz inne urządzenia elektryczne.
   - Sensory - to urządzenia, które zbierają informacje o środowisku w domu, takie jak temperatura, wilgotność, poziom oświetlenia i inne. Te informacje są przekazywane do kontrolera inteligentnego, który na ich podstawie podejmuje decyzje dotyczące działania urządzeń.
   - Urządzenia do automatyzacji domu - to urządzenia, które umożliwiają automatyzację różnych czynności w domu, takich jak otwieranie drzwi, włączanie i wyłączanie oświetlenia i urządzeń, ustawianie temperatury, itp.
   - Sieć komputerowa - to infrastruktura sieciowa, która umożliwia komunikację między poszczególnymi elementami systemu. W zależności od potrzeb, sieć może być przewodowa lub bezprzewodowa.
   - Aplikacje mobilne - to oprogramowanie, które umożliwia zdalne sterowanie urządzeniami z poziomu smartfona lub tabletu. Dzięki aplikacjom można np. zmieniać ustawienia temperatury, włączać i wyłączać oświetlenie, itp.
   - Chmura - to usługa, która umożliwia przechowywanie i przetwarzanie danych w Internecie. Chmura może być wykorzystana do zdalnego przechowywania danych z sensorów i innych urządzeń, a także do wykonywania obliczeń na danych.
   - Systemy bezpieczeństwa - to urządzenia, które umożliwiają monitorowanie bezpieczeństwa w domu, takie jak kamery, czujniki ruchu, systemy alarmowe i inne. Te urządzenia są połączone z kontrolerem inteligentnym, co pozwala na szybką reakcję w przypadku wykrycia zagrożenia.

1. **W jakim celu stosuje się przetwarzanie w Chmurze.**

   Przetwarzanie w chmurze (ang. cloud computing) to model dostarczania usług informatycznych, w którym zasoby, takie jak serwery, sieci, aplikacje i dane, są udostępniane przez dostawcę usług za pośrednictwem internetu. Przetwarzanie w chmurze umożliwia użytkownikom elastyczny i skalowalny dostęp do zasobów informatycznych, dzięki czemu mogą one szybciej i taniej rozwijać swoje aplikacje, przetwarzać duże ilości danych i udostępniać je swoim użytkownikom.

   Przetwarzanie w chmurze umożliwia przedsiębiorstwom i użytkownikom indywidualnym korzystanie z zaawansowanych usług informatycznych, takich jak analiza danych, sztuczna inteligencja, uczenie maszynowe, wirtualizacja i wiele innych, bez konieczności posiadania wlasnego sprzętu, oprogramowania i infrastruktury sieciowej. Przetwarzanie w chmurze pozwala na zwiększenie wydajności i elastyczności, a także na obniżenie kosztów operacyjnych i inwestycyjnych.

   W przypadku Internetu rzeczy (IoT), przetwarzanie w chmurze jest szczególnie przydatne ze względu na duże ilości danych, które muszą być gromadzone, przetwarzane i analizowane w czasie rzeczywistym. Przetwarzanie w chmurze umożliwia szybkie i wydajne przetwarzanie danych z urządzeń IoT, a także umożliwia tworzenie inteligentnych aplikacji i rozwiązań, które mogą reagować na zmiany w otoczeniu i wykorzystywać dane do lepszego zarządzania zasobami i procesami.

1. **Jakie rozwiązania stosowane są do wymiany informacji w systemach IoT.**

   W systemach IoT (Internetu Rzeczy) informacje są wymieniane pomiędzy urządzeniami oraz między urządzeniami a serwerami lub chmurami. Istnieje wiele różnych rozwiązań stosowanych do wymiany informacji w systemach IoT, w tym:

   - Protokoły sieciowe: Wiele protokołów sieciowych, takich jak HTTP, MQTT czy CoAP, jest stosowanych w IoT do wymiany danych pomiędzy urządzeniami i serwerami.
   - Brokerzy MQTT: Broker MQTT (Message Queuing Telemetry Transport) służy do przesyłania wiadomości między urządzeniami w sposób bezpieczny i niezawodny.
   - RESTful APIs: REST (Representational State Transfer) to popularny styl architektury oprogramowania stosowany do tworzenia API (Application Programming Interface). RESTful APIs są często stosowane w IoT do wymiany informacji między urządzeniami i aplikacjami w chmurze.
   - AMQP (Advanced Message Queuing Protocol): AMQP to protokół przesyłania wiadomości, który jest wykorzystywany do wymiany informacji pomiędzy aplikacjami w chmurze. Jest to protokół typu publish/subscribe, co oznacza, że urządzenia publikują informacje, a aplikacje w chmurze je subskrybują.
   - Websockets: Websockets to protokół komunikacji, który umożliwia komunikację w czasie rzeczywistym między urządzeniami i aplikacjami w chmurze. Jest to szczególnie przydatne w przypadku przesyłania informacji w czasie rzeczywistym, takich jak informacje z czujników.
   - OPC UA (Open Platform Communications Unified Architecture): OPC UA to protokół przemysłowy, który umożliwia bezpieczną i niezawodną wymianę danych między urządzeniami i aplikacjami w chmurze.
   - Bluetooth i BLE (Bluetooth Low Energy): Bluetooth i BLE są stosowane do komunikacji między urządzeniami IoT, szczególnie w przypadku urządzeń o niskim poborze mocy, takich jak czujniki i urządzenia noszone.
   - LoRaWAN (Long Range Wide Area Network): LoRaWAN to technologia sieci bezprzewodowych, która umożliwia komunikację na dużych odległościach z niskim poborem mocy. Jest to szczególnie przydatne w przypadku IoT, w którym urządzenia często są rozmieszczone na dużych obszarach.

1. **W jaki sposób systemy IoT minimalizują zapotrzebowanie na zasilanie.**

   Systemy IoT, czyli internetu rzeczy, starają się minimalizować zapotrzebowanie na zasilanie w celu zapewnienia długiego czasu działania i niezawodności urządzeń. Oto kilka sposobów, w jakie systemy IoT minimalizują zapotrzebowanie na energię:

   - Uspienie urządzeń: Urządzenia IoT są często zaprojektowane do wybudzania się tylko wtedy, gdy jest to konieczne. W ten sposób minimalizuje się zużycie energii podczas bezczynności.
   - Zastosowanie technologii niskiego poboru mocy (LPWAN): Wprowadzenie technologii LPWAN do systemów IoT umożliwia transmisję danych na duże odległości z minimalnym zużyciem energii.
   - Optymalizacja sieci: Dobre zaprojektowanie sieci IoT może pomóc w minimalizacji zużycia energii. Przykładowo, zastosowanie topologii gwiazdy pozwala na oszczędzanie energii przez ograniczenie ilości niepotrzebnych transmisji.
   - Zastosowanie baterii lub innych źródeł energii: Urządzenia IoT często korzystają z baterii lub innych źródeł energii, takich jak panele słoneczne lub generatory termoelektryczne, aby zapewnić długie czasu działania bez potrzeby podłączania do sieci zasilającej.
   - Optymalizacja algorytmów: Algorytmy wykorzystywane w systemach IoT mogą być zoptymalizowane pod kątem minimalizacji zużycia energii poprzez ograniczenie niepotrzebnych obliczeń lub transmisji danych.
   - Zastosowanie inteligentnych czujników: Inteligentne czujniki w systemach IoT pozwalają na mierzenie tylko tych parametrów, które są konieczne, co minimalizuje zużycie energii.

## INŻYNIERIA GIER KOMPUTEROWYCH, GRAFIKA KOMPUTEROWA W GRACH

1. **Scharakteryzuj dwie wybrane metody prototypowania graficznego. Podaj ich mocne i słabe strony.**

   Metoda mockup-ów: polega na tworzeniu statycznych wizualizacji interfejsu użytkownika zanim rozpocznie się tworzenie grafik i animacji. Mocną stroną jest szybkie i łatwe tworzenie prototypów, słabą stroną brak możliwości testowania interakcji z użytkownikiem.

   Metoda wireframe: polega na tworzeniu uproszczonych schematów, które przedstawiają podstawowe elementy interfejsu użytkownika i ich wzajemne powiązania. Mocną stroną jest szybkość tworzenia, słabą brak możliwości dokładnego zaprojektowania grafiki.

1. **Omów narzędzia modelowania i prototypowania graficznego, podaj ich mocne i słabe strony.**

   Blender: narzędzie służące do tworzenia modeli 3D i animacji. Mocną stroną jest duża ilość dostępnych funkcji i pluginów, słabą potrzeba dużej ilości czasu i wiedzy, by osiągnąć dobre efekty.

   Adobe XD: narzędzie do projektowania interfejsów użytkownika. Mocną stroną jest łatwość w użyciu i integracja z innymi narzędziami Adobe, słabą brak możliwości tworzenia zaawansowanych animacji.

1. **Wyjaśnij na czym polega przygotowanie obiektów do animacji.**

   Przygotowanie obiektów do animacji polega na nadaniu im właściwej geometrii, teksturom, materiałom oraz szkieletowi animacyjnemu, który pozwala na ruch poszczególnych elementów obiektu.

1. **Na czym polega przygotowanie wirtualnych przestrzeni gier.**

   Przygotowanie wirtualnych przestrzeni gier polega na stworzeniu trójwymiarowego świata z wykorzystaniem różnych technologii graficznych, takich jak modelowanie 3D, texturing, shading, oświetlenie czy animacja postaci i obiektów.

1. **Porównaj dwa wybrane narzędzia do przygotowania graficznej prezentacji gry.**

   Unity: środowisko programistyczne i silnik gier, pozwalające na tworzenie gier dla wielu platform. Mocną stroną jest łatwość w użyciu, słabą brak zaawansowanych funkcji.

   Unreal Engine: silnik gier, który pozwala na tworzenie gier na wiele platform. Mocną stroną jest duża ilość dostępnych funkcji i narzędzi, słabą skomplikowany interfejs.

1. **Jakie czynniki mają wpływ na opracowanie koncepcji, analizy założeń i wymagań projektowych gry.**

   Do czynników, które mają wpływ na opracowanie koncepcji, analizy założeń i wymagań projektowych gry zalicza się m.in. cel gry, grupę docelową, środowisko, w którym gra będzie działać, budżet, czas realizacji projektu.

1. **Przedstaw kolejne kroki procesu projektowania gry komputerowej.**

   Kolejne kroki procesu projektowania gry komputerowej to m.in. ustalenie koncepcji gry, tworzenie dokumentacji, projektowanie interfejsu użytkownika, modelowanie postaci i obiektów, tworzenie animacji i efekt

1. **Porównaj projektowanie gry jednoplatformowej z wieloplatformową.**

   Projektowanie gier jednoplatformowych polega na opracowaniu gry dla jednej platformy, np. dla konsoli Xbox lub komputera osobistego. Zaletą takiego podejścia jest łatwiejsze dostosowanie gry do specyfikacji danej platformy oraz zwiększenie wydajności i stabilności gry. Wadą jest jednak mniejsza liczba potencjalnych graczy, którzy nie posiadają tej konkretnej platformy.

   Projektowanie gier wieloplatformowych polega na opracowaniu gry tak, aby była ona dostępna na różnych platformach, np. komputerach osobistych, konsolach, urządzeniach mobilnych. Zaletą takiego podejścia jest zwiększenie zasięgu i dostępności gry dla większej liczby graczy oraz możliwość osiągnięcia większego zysku. Wadą może być konieczność dostosowania gry do specyfikacji różnych platform, co może prowadzić do większych kosztów produkcji oraz trudności w zachowaniu stabilności i wydajności gry na wszystkich urządzeniach.

1. **Podaj różnice pomiędzy silnikami gier, a platformami gier.**

   Silnik gry to program komputerowy, który służy do tworzenia gier komputerowych. Zawiera on wiele modułów i bibliotek umożliwiających m.in. tworzenie grafiki, dźwięków, sztucznej inteligencji czy mechaniki rozgrywki. Platforma gier natomiast to sprzęt lub oprogramowanie, na którym uruchamiane są gry.

   Podstawowa różnica między silnikami gier a platformami gier polega na tym, że silnik gry jest oprogramowaniem, które umożliwia tworzenie gier na różne platformy, natomiast platforma gier to sprzęt lub oprogramowanie, na którym dana gra może działać.

1. **Na czym polega dostosowanie projektu gry do rożnych platform**

   Dostosowanie projektu gry do różnych platform polega na tym, aby zapewnić, że gra będzie działała poprawnie na każdej z platform, na której ma być uruchamiana. W zależności od platformy, wymagane są różne specyfikacje sprzętowe, systemy operacyjne czy interfejsy programowania aplikacji (API).

   Dostosowanie projektu gry do różnych platform może obejmować takie kroki jak:

   - Zoptymalizowanie grafiki i kodu gry pod kątem specyfikacji sprzętowej danej platformy
   - Dostosowanie interfejsu użytkownika do różnych rozmiarów ekranów
   - Wykorzystanie odpowiednich bibliotek i interfejsów programowania aplikacji (API) dla danej platformy
   - Testowanie gry na różnych platformach, aby upewnić się, że działa poprawnie.
